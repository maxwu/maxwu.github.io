<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>+U Maxout!</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://maxwu.me/"/>
  <updated>2021-10-24T22:03:14.510Z</updated>
  <id>http://maxwu.me/</id>
  
  <author>
    <name>Max Wu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Using Multi-Stage Build to Reduce Docker Image Size</title>
    <link href="http://maxwu.me/2019/11/24/Using-Multi-Stage-Build-to-Reduce-Docker-Image-Size/"/>
    <id>http://maxwu.me/2019/11/24/Using-Multi-Stage-Build-to-Reduce-Docker-Image-Size/</id>
    <published>2019-11-24T10:51:09.000Z</published>
    <updated>2021-10-24T22:03:14.510Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://imgur.com/adsP1G1"><img src="https://i.imgur.com/adsP1G1t.png" alt="Docker on the Producing Line"></a></p><p>The multi-stage supports in docker image building was introduced with Docker v17.05 in 2017. This post summarizes the practical points which can benefit the development experience, secure the data and reduce the docker image size.</p><span id="more"></span><h2 id="Multi-Stage-in-Docker-Image-Building"><a href="#Multi-Stage-in-Docker-Image-Building" class="headerlink" title="Multi-Stage in Docker Image Building"></a>Multi-Stage in Docker Image Building</h2><p>The multi-stage docker image build, in my practices, shows a way to resolve thress issues. </p><ul><li><p>Data Security Supports: If there are previous steps to download the source, setting up the toolchain then there is a risk to leak information via incomplete deletion or to introudce more vulnerability by leaving the artifacts building toolchain on product images. Some cloud solution vendor offers special solution to build artifacts with homogeneous images and only delivery final artifacts in last image. </p></li><li><p>Reducing Docker Image Size: Docker image build generate new layer on each command and the AUFS applies <code>Lazy Deletion</code>. If caches and temporary files are removed in second command, the size wouldn’t be reduced from volume but just those files are marked as deleted in the new layer. As pointed by many <code>Dockerfile Best Practice</code> or guidelines, there are recommended tricky steps to keep the <code>dotnet build</code>, <code>yun install</code> or <code>apt-get install</code> followed by purges. Multi-stage build could resolve it by copying artifacts from another stage.</p></li><li><p>Easy to Maintain Dockerfile: The above two issues could be mitigated with well configured multiple images in a procedure to deliver the final artifacts only in last image. However, the Dockerfiles would have dependencies and the Dockerfile would be hard to maintain.</p></li></ul><p>Multi-stage build was introduced to divide the docker image build into multiple stages which can pass artifacts from one to another and eventually ship the final artifacts in the last stage. </p><h2 id="Examples-to-Reduce-Docker-Image"><a href="#Examples-to-Reduce-Docker-Image" class="headerlink" title="Examples to Reduce Docker Image"></a>Examples to Reduce Docker Image</h2><p>Take an example of upgrading googl-chrome browser version. The base image is <code>cypress/browers</code>. </p><h3 id="Upgrade-Google-Chrome-without-Purging-the-Cache"><a href="#Upgrade-Google-Chrome-without-Purging-the-Cache" class="headerlink" title="Upgrade Google-Chrome without Purging the Cache"></a>Upgrade Google-Chrome without Purging the Cache</h3><p>The Dockefile is straight through:<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FROM cypress/browsers:node11.13.0-chrome73</span><br><span class="line"></span><br><span class="line">ENV TZ=Pacific/Auckland</span><br><span class="line"></span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install google-chrome-stable -y &amp;&amp; \</span><br><span class="line">    google-chrome --version</span><br></pre></td></tr></table></figure></p><p>From the logs, it shows chrome browser v78 replaced original v73. To check the image size, either <code>docker images</code> with labels/tags to show a summary on matched images or <code>docker inspect</code> command can show image details.</p><p>Then <code>docker inspect cypress3-chrome-updated-without-purge | jq &#39;.[0].Size&#39;</code> would show the image szie <code>1520046216</code> in Bytes. Alternatively, the docker command native <code>JSON</code> filer could be applied to get the same result on given image <code>docker inspect cypress3-chrome-updated-without-purge --format=&#39;\&#123;\&#123;.Size\&#125;\&#125;&#39;</code>.</p><h3 id="Upgrade-Google-Chrome-and-Purge-the-Cache-Immediately"><a href="#Upgrade-Google-Chrome-and-Purge-the-Cache-Immediately" class="headerlink" title="Upgrade Google-Chrome and Purge the Cache Immediately"></a>Upgrade Google-Chrome and Purge the Cache Immediately</h3><p>Apply the recommended hacks to clean the cache on every command:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FROM cypress/browsers:node11.13.0-chrome73</span><br><span class="line"></span><br><span class="line">ENV TZ=Pacific/Auckland</span><br><span class="line"></span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install google-chrome-stable \</span><br><span class="line">    -y --no-install-recommends &amp;&amp; \</span><br><span class="line">    rm -rf /var/lib/apt/lists/* &amp;&amp; \</span><br><span class="line">    google-chrome --version</span><br></pre></td></tr></table></figure><p>This way the image size is reduced to 1503569359 Bytes. 200MB caches are removed from the same layer to upgrade chrome browser.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; docker inspect cypress3-chrome-updated-cache-purged  --format=&#x27;&#123;&#123;.Size&#125;&#125;&#x27;</span><br><span class="line">&gt; 1503569359</span><br></pre></td></tr></table></figure><p>Obviously the Dockerfile is a bit harder to maintain because each step was appended with all kinds of purge commands. If there is no convenient way to purge right away or it is difficult to maintain such code in one command, a script might be drafted and copied to the intermediate layers to support such a command in one step.</p><h3 id="Generate-the-Same-Image-in-Multi-Stage-Build"><a href="#Generate-the-Same-Image-in-Multi-Stage-Build" class="headerlink" title="Generate the Same Image in Multi-Stage Build"></a>Generate the Same Image in Multi-Stage Build</h3><p>With a quick check, the google chrome is maintained in <code>/opt/google/chrome</code> folder and as an image for experiments, it is okay not to consider apt-get checksums. The new Dockerfile is drafted as below:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FROM cypress/browsers:node11.13.0-chrome73 as stage1</span><br><span class="line"></span><br><span class="line">ENV TZ=Pacific/Auckland</span><br><span class="line"></span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install google-chrome-stable \</span><br><span class="line">    -y --no-install-recommends &amp;&amp; \</span><br><span class="line">    rm -rf /var/lib/apt/lists/* &amp;&amp; \</span><br><span class="line">    google-chrome --version</span><br><span class="line"></span><br><span class="line">FROM cypress/browsers:node11.13.0-chrome73</span><br><span class="line">COPY --from=stage1 /opt/google/chrome /opt/google/chrome</span><br><span class="line">RUN google-chrome --version</span><br></pre></td></tr></table></figure><p>The first image is also homogeneous and it just contribute the google-chrome binary files. Then the final image <code>copied</code> the binaries directly to corresponding folder.</p><p>Test the google-chrome version in cli.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; docker run -it cypress3-chrome-updated-multi-stages google-chrome --version</span><br><span class="line">&gt; Google Chrome 78.0.3904.108</span><br></pre></td></tr></table></figure><p>Check the image size and it shows even a smaller size than that from Dockerfile to purge apt-get system caches because this solution only copies the required folder.</p><p><code>docker inspect cypress3-chrome-updated-multi-stages  --format=&#39;\&#123;\&#123;\.Size\&#125;\&#125;&#39;</code> reports size as <code>1501127204</code> Bytes.</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul><li><p>Less information left on image: No need to keep addition YUM repos if it is an RHEL image, no extra keys left, more important, no development phase configuration or source code left on image.</p></li><li><p>Smaller size: Since copying the artifacts is the clean way to add only requested files to final image, the size is only increased for neccessary. </p></li></ul><table><thead><tr><th>Building way</th><th style="text-align:center">Size</th></tr></thead><tbody><tr><td>Install pkg from apt-get</td><td style="text-align:center">1520046216</td></tr><tr><td>Install pkg and purge</td><td style="text-align:center">1503569359</td></tr><tr><td>Copying binaries from previous stage</td><td style="text-align:center">1501127204</td></tr></tbody></table><h2 id="Further-Discussion"><a href="#Further-Discussion" class="headerlink" title="Further Discussion"></a>Further Discussion</h2><p>A better chance to apply multi-stage docker image building is to support multi-stage compilation. One typical example is to upgrade git version on an RHEL Jenkins Slave Image. RHEL official YUM repo only supplies the old version of git client. Which doesn’t support the advanced functions as Dotnet Core NuGet operations. In this case, the solution is to download git source code and install gcc toolchain to build it locally. Without multi-stage image build, the procedure would request a cross compilation on source code in separate script or build it on docker image directly for homogeneous arch. Multi-stage docker image build can maintain the steps in one single Dockerfile.</p><p>On the other side, the sample in this post is not an apt example. If only the chrome binary executable files under /opt/google/chrome are updated staightly, the /etc/alternative would still point to chrome-stable binary but the apt pkg management DB still regard it as the original version v73, not the current version and the dependencies check won’t cover v78 neither. Like Sun Solaris package system, it is possible to overwrite the package DB but which would request one more command and consequently a new docker image layer. The apt package DB is located at /var/lib/apt/lists. </p><p>So apply multi-stage image build for source code compilation especially multi-stage compilation, decompressed binary package as Node.js.  </p><p>(TBC)</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://imgur.com/adsP1G1&quot;&gt;&lt;img src=&quot;https://i.imgur.com/adsP1G1t.png&quot; alt=&quot;Docker on the Producing Line&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The multi-stage supports in docker image building was introduced with Docker v17.05 in 2017. This post summarizes the practical points which can benefit the development experience, secure the data and reduce the docker image size.&lt;/p&gt;
    
    </summary>
    
      <category term="DevOps" scheme="http://maxwu.me/categories/DevOps/"/>
    
      <category term="Docker" scheme="http://maxwu.me/categories/DevOps/Docker/"/>
    
    
      <category term="Docker" scheme="http://maxwu.me/tags/Docker/"/>
    
      <category term="Cloud" scheme="http://maxwu.me/tags/Cloud/"/>
    
  </entry>
  
  <entry>
    <title>Still On the Way to Cloud</title>
    <link href="http://maxwu.me/2019/11/11/Still-On-the-Way-to-Cloud/"/>
    <id>http://maxwu.me/2019/11/11/Still-On-the-Way-to-Cloud/</id>
    <published>2019-11-11T10:00:20.000Z</published>
    <updated>2021-10-25T11:10:09.459Z</updated>
    
    <content type="html"><![CDATA[<p>It is the last quarter of 2019. A large number of organizations already deployed docker containerized applications in production environment and usually the services are orchestrated with kubernetes or Openshift. As the well known saying, just moving applications to cloud doesn’t mean clouding, we are still in the middle of way to cloud. This post is also a retrospective on the issues discovered this year on migrating traditional technical stacks to cloud. </p><p>(WIP)</p><p><img src="https://i.imgur.com/zApN0Gsm.jpg" alt="Docker_Kube"></p><span id="more"></span><h2 id="1-Typical-issues-on-sensitivity-of-container-environment"><a href="#1-Typical-issues-on-sensitivity-of-container-environment" class="headerlink" title="1 Typical issues on sensitivity of container environment"></a>1 Typical issues on sensitivity of container environment</h2><h3 id="1-1-Dotnet-core-2-1-Pod-restarted-on-OOM-Killer"><a href="#1-1-Dotnet-core-2-1-Pod-restarted-on-OOM-Killer" class="headerlink" title="1.1 Dotnet core 2.1 Pod restarted on OOM Killer"></a>1.1 Dotnet core 2.1 Pod restarted on OOM Killer</h3><p>This was the first issue I spent a big effort this year to realize that popular technical stacks were still not ready to adapt themselves to container environment. Typically if a managed system reads the mount point <code>/proc/self/mountinfo</code> as on regular Linux platform but not the <code>/proc/self/cgroup</code>, the memory limits are not observable from the memory management. </p><p>The github link is <a href="https://github.com/dotnet/coreclr/issues/13489">https://github.com/dotnet/coreclr/issues/13489</a>. The fix includes <a href="https://github.com/dotnet/coreclr/pull/13488">https://github.com/dotnet/coreclr/pull/13488</a> and <a href="https://github.com/dotnet/coreclr/pull/15297">https://github.com/dotnet/coreclr/pull/15297</a> to check cgroup resource limits and expose docker processor counts to CLR environments. </p><p>The phenomenon was dotnet core pod restarted more than 200 times per day and openshift monitor portal showed <code>OOM Killer</code> in event description. It was lukcy the production environment deployed with replica number 4 so fintech service was not interrupted. To debug this issue, an image of LLDB on dotnet core was created to detect threading model and high memory blocks (<a href="https://maxwu.me/2019/04/15/Debug-dotnet-core-with-LLDB-on-RHEL-Image/)">https://maxwu.me/2019/04/15/Debug-dotnet-core-with-LLDB-on-RHEL-Image/)</a>. Per my observation, the high runners are Newtonsoft JSON entities because lots of memory were consumed by dotnet string buffers. </p><h3 id="1-2-Jenkins-Pipeline-ran-out-of-memory"><a href="#1-2-Jenkins-Pipeline-ran-out-of-memory" class="headerlink" title="1.2 Jenkins Pipeline ran out of memory"></a>1.2 Jenkins Pipeline ran out of memory</h3><p>This issue is actually a JVM configuration problem. It was dicovered when Jenkins pod ran slowly in one day and Jenkins pod was observed to restart within 72hr everytime. Our Pipeline was a typical Jenkins groovy Pipeline and it communicated to two kinds of slaves: (1) the dynamical jenkins slave created on demand, which were based on different slave images with required technical stack; (2) windows slaves for specific tasks which could only complete by Windows nodes for time being.</p><p>(TBC)</p><h3 id="1-3-Cypress-failed-to-launch-XVFB-in-docker-container"><a href="#1-3-Cypress-failed-to-launch-XVFB-in-docker-container" class="headerlink" title="1.3 Cypress failed to launch XVFB in docker container"></a>1.3 Cypress failed to launch XVFB in docker container</h3><p>Cypress is the in browser javascript UI test framework I picked for team last year (2018) when migrated from host based Selenium to Pipeline. </p><p>(TBC)</p><h2 id="2-Typical-issues-on-container-orchestration"><a href="#2-Typical-issues-on-container-orchestration" class="headerlink" title="2 Typical issues on container orchestration"></a>2 Typical issues on container orchestration</h2><h3 id="2-1-Orchestrating-Cypress-tests-in-Map-Reduce-model-on-kube-cloud"><a href="#2-1-Orchestrating-Cypress-tests-in-Map-Reduce-model-on-kube-cloud" class="headerlink" title="2.1 Orchestrating Cypress tests in Map-Reduce model on kube cloud"></a>2.1 Orchestrating Cypress tests in Map-Reduce model on kube cloud</h3><h3 id="2-2-Rolling-out-springboot-pod-generated-alert-flooding-on-splunk"><a href="#2-2-Rolling-out-springboot-pod-generated-alert-flooding-on-splunk" class="headerlink" title="2.2 Rolling out springboot pod generated alert flooding on splunk"></a>2.2 Rolling out springboot pod generated alert flooding on splunk</h3><h2 id="3-Retrospective"><a href="#3-Retrospective" class="headerlink" title="3 Retrospective"></a>3 Retrospective</h2><h2 id="Change-Log"><a href="#Change-Log" class="headerlink" title="Change Log"></a>Change Log</h2><p>Nov 12, 2019: Initial post with intro part and the outline.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;It is the last quarter of 2019. A large number of organizations already deployed docker containerized applications in production environment and usually the services are orchestrated with kubernetes or Openshift. As the well known saying, just moving applications to cloud doesn’t mean clouding, we are still in the middle of way to cloud. This post is also a retrospective on the issues discovered this year on migrating traditional technical stacks to cloud. &lt;/p&gt;
&lt;p&gt;(WIP)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/zApN0Gsm.jpg&quot; alt=&quot;Docker_Kube&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="DevOps" scheme="http://maxwu.me/categories/DevOps/"/>
    
      <category term="Docker" scheme="http://maxwu.me/categories/DevOps/Docker/"/>
    
    
      <category term="Docker" scheme="http://maxwu.me/tags/Docker/"/>
    
      <category term="Openshift" scheme="http://maxwu.me/tags/Openshift/"/>
    
      <category term="Cloud" scheme="http://maxwu.me/tags/Cloud/"/>
    
  </entry>
  
  <entry>
    <title>A Bite of SpringBoot</title>
    <link href="http://maxwu.me/2019/09/28/A-Bite-Of-Springboot/"/>
    <id>http://maxwu.me/2019/09/28/A-Bite-Of-Springboot/</id>
    <published>2019-09-28T08:37:33.000Z</published>
    <updated>2021-10-24T22:03:14.503Z</updated>
    
    <content type="html"><![CDATA[<p>The journey to migrate dotnet experiences to springboot and build a demo app from scratch, deploy it to kubernetes with explanation on technical points and the cloud native practice notes.</p><span id="more"></span><h2 id="Backgounds"><a href="#Backgounds" class="headerlink" title="Backgounds"></a>Backgounds</h2><p>As a pythonist on system level, I built several my experience with Java Web Frameworks are mostly on structs MVC as an UI backend to interact with JQuery to present the status and management from message security gateway products. However, according to the reality of circumstance, framework seems much more impressive than computer science and ways of thoughts. </p><p>It’s the time to take a bite on Springboot and see what’s inside. </p><h2 id="1-Environment"><a href="#1-Environment" class="headerlink" title="1 Environment"></a>1 Environment</h2><p>In brief, Jetbrain IntelliJ community version on Mac. I used to program Python on PyCharm and IntelliJ shares similar features on Java IDE.</p><p>Java toolchain will be organized in Gradle. Maven is an alternative which I used in previous test automation tools. However, gradle is graceful and brief.</p><p>Eventually the service will be wrapped in kubernetes pod but it is not the first step.</p><h2 id="2-Create-A-New-Springboot-App"><a href="#2-Create-A-New-Springboot-App" class="headerlink" title="2 Create A New Springboot App"></a>2 Create A New Springboot App</h2><p>Springboot web site offers <code>curl</code> interface to generate a demo project to start from. Visit <a href="https://start.spring.io">https://start.spring.io</a> on cli tool curl will show the manual on how to generate springboot scaffold.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl https://start.spring.io</span><br><span class="line"># The response shows a manual page with below samples.</span><br><span class="line">Examples:</span><br><span class="line"></span><br><span class="line">To create a default demo.zip:</span><br><span class="line">$ curl https://start.spring.io/starter.zip -o demo.zip</span><br><span class="line"></span><br><span class="line">To create a web project using Java 11:</span><br><span class="line">$ curl https://start.spring.io/starter.zip -d dependencies=web \\</span><br><span class="line">-d javaVersion=11 -o demo.zip</span><br><span class="line"></span><br><span class="line">To create a web/data-jpa gradle project unpacked:</span><br><span class="line">$ curl https://start.spring.io/starter.tgz -d dependencies=web,data-jpa \\</span><br><span class="line">   -d type=gradle-project -d baseDir=my-dir | tar -xzvf -</span><br><span class="line"></span><br><span class="line">To generate a Maven POM with war packaging:</span><br><span class="line">$ curl https://start.spring.io/pom.xml -d packaging=war -o pom.xml</span><br></pre></td></tr></table></figure><p>I chose a demo web project using Java 8. Which means, a wrapped dependency of <code>spring-boot-starter-web</code>. Springboo will interrepte it to real dependencies.</p><p><code>curl https://start.spring.io/starter.zip -d dependencies=web -d javaVersion=8 -d type=gradle-project -o demo.zip</code></p><p>Alternatively, open IntelliJ menu to “New Project” will also provide options to visit <code>start.spring.io</code> within the IDE UI to create project scaffold.</p><h2 id="3-Launch-Springboot-Demo"><a href="#3-Launch-Springboot-Demo" class="headerlink" title="3 Launch Springboot Demo"></a>3 Launch Springboot Demo</h2><p>When importing the scaffold project to IntelliJ, a run configuration with main class on the <code>DemoApplication</code> , where the annotation <code>@SpringBootApplication</code> is applied, will be created. Run the configuration “DemoApplication” will launch Springboo web app in couple of seconds. However, visiting <code>localhost:8080</code> will still return an error page since there is nothing to respond.</p><p>For the gradle configured project, the IntelliJ would spend a bit while to download gradle dependencies.</p><p>A simple controller class is added to respond string content to path <code>/</code>. Thanks to IntelliJ, the annotations are auto-completed. Key points here are “GetMapping” annotation to specify the path of <code>/</code> and “RespenseBody” annotation t</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.demo;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Controller;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.GetMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.ResponseBody;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MainController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/&quot;)</span></span><br><span class="line">    <span class="meta">@ResponseBody</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">home</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Home&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Like <code>npm run</code> but more verbose than the node.js cmd, luanch <code>./gradlew tasks</code> or directly run <code>gradle tasks</code> in root folder of project would print out a task list which can be run by gradle plugin. If it is the first time running <code>gradle</code>, the gradle daemon shall be luanched and basic environment/dependencies checks would be performed first.</p><p><code>gradlew</code> and <code>gradle.bat</code> are artifacts generated by <code>gradle warpper</code> task which empower environments with gradle preinstalled to run gradle toolchain commands.</p><p>After updating the above controller class, run <code>gradle bootRun</code> would also run the springboot application to server <code>localhost:8080</code>. In the browser, the simple content “Home” is fetched and rendered.</p><h2 id="4-Build-Docker-Image-for-Springboot-App"><a href="#4-Build-Docker-Image-for-Springboot-App" class="headerlink" title="4 Build Docker Image for Springboot App"></a>4 Build Docker Image for Springboot App</h2><p>As usual there are multiple ways to build docker images as first step to containerize the app. Thanks to the gradle community <code>com.palantir.docker</code> plugin is picked up in this demo project.</p><p>The gradle pluin could be applied in build.script DSL or plugin DSL. This experiment applies the plugin DSL and build docker image with Dockerfile rather than docker plugin DSL to reuse author’s existing Dockerfile experiences for now.</p><h3 id="4-1-Add-Plugin"><a href="#4-1-Add-Plugin" class="headerlink" title="4.1 Add Plugin"></a>4.1 Add Plugin</h3><p>Insert this plugin reference to build.gradle <code>id &#39;com.palantir.docker&#39; version &#39;0.22.1&#39;</code>.</p><h3 id="4-2-Introduce-docker-Task"><a href="#4-2-Introduce-docker-Task" class="headerlink" title="4.2 Introduce docker Task"></a>4.2 Introduce <code>docker</code> Task</h3><p>The task is defined as below:</p><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">docker &#123;</span><br><span class="line">dependsOn build</span><br><span class="line">name <span class="string">&quot;$&#123;project.group&#125;/$&#123;bootJar.baseName&#125;&quot;</span></span><br><span class="line">files bootJar.archivePath</span><br><span class="line">buildArgs([<span class="string">&#x27;JAR_FILE&#x27;</span>: <span class="string">&quot;$&#123;bootJar.archiveName&#125;&quot;</span>])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-3-Create-the-Dockerfile"><a href="#4-3-Create-the-Dockerfile" class="headerlink" title="4.3 Create the Dockerfile"></a>4.3 Create the Dockerfile</h3><p>To keep the image slim, alpine jdk8 image is picked as base image. </p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> openjdk:<span class="number">8</span>-jdk-alpine</span><br><span class="line"><span class="keyword">VOLUME</span><span class="bash"> /tmp</span></span><br><span class="line"><span class="keyword">ARG</span> JAR_FILE</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> <span class="variable">$&#123;JAR_FILE&#125;</span> app.jar</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">&quot;java&quot;</span>,<span class="string">&quot;-Djava.security.egd=file:/dev/./urandom&quot;</span>,<span class="string">&quot;-jar&quot;</span>,<span class="string">&quot;/app.jar&quot;</span>]</span></span><br></pre></td></tr></table></figure><h3 id="4-4-Launch-Container-Locally"><a href="#4-4-Launch-Container-Locally" class="headerlink" title="4.4 Launch Container Locally"></a>4.4 Launch Container Locally</h3><p>With above Dockerfile and the     <code>docker</code> task inserted to gradle.build script, run <code>gradle docker</code> would (re)build the app image with dependencies. Quickly test the docker image by launching it locally, <code>docker run -p 8080:8080 -t com.example/demo</code>. Then open browser on URL <code>http://localhost:8080/</code> the same contents are responded “Home”.</p><h2 id="5-Deploy-to-Kubernetes"><a href="#5-Deploy-to-Kubernetes" class="headerlink" title="5 Deploy to Kubernetes"></a>5 Deploy to Kubernetes</h2><p>(To be continued)</p><h2 id="Change-Log"><a href="#Change-Log" class="headerlink" title="Change Log"></a>Change Log</h2><p>Sep 22, 2019: Configuration and start a new springboot app.<br>Sep 28, 2019: </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The journey to migrate dotnet experiences to springboot and build a demo app from scratch, deploy it to kubernetes with explanation on technical points and the cloud native practice notes.&lt;/p&gt;
    
    </summary>
    
      <category term="Microservice" scheme="http://maxwu.me/categories/Microservice/"/>
    
      <category term="Springboot" scheme="http://maxwu.me/categories/Microservice/Springboot/"/>
    
    
      <category term="Java" scheme="http://maxwu.me/tags/Java/"/>
    
      <category term="Springboot" scheme="http://maxwu.me/tags/Springboot/"/>
    
      <category term="Kubernetes" scheme="http://maxwu.me/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Fix home brew updating failure</title>
    <link href="http://maxwu.me/2019/08/17/Fix-home-brew-updating-failure/"/>
    <id>http://maxwu.me/2019/08/17/Fix-home-brew-updating-failure/</id>
    <published>2019-08-17T11:21:51.000Z</published>
    <updated>2021-10-24T22:03:14.505Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h2 id="Problem-Description"><a href="#Problem-Description" class="headerlink" title="Problem Description"></a>Problem Description</h2><p>After a few weeks sorting up and working with Python3 on my Mac Book Pro, the brew update failed to update and reported an error of aws command not found.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; brew update</span><br><span class="line">aws codecommit credential-helper $@ get: aws: command not found</span><br><span class="line">fatal: could not read Username for &#x27;https://github.com/Homebrew/homebrew-boneyard&#x27;: terminal prompts disabled</span><br><span class="line"></span><br><span class="line">^Cerror: https://github.com/caskroom/homebrew-cask did not send all necessary objects</span><br></pre></td></tr></table></figure><h2 id="Resolution"><a href="#Resolution" class="headerlink" title="Resolution"></a>Resolution</h2><p>The solution is straight through. Since aws cli is not found, it is a missed step in migrating Mac development environment from Python2 to Python3 – the corresponding aws cli is not installed well to Python3. </p><p>My python environment is managed via PyEnv. When a new python version is installed, the upstream depeendencies are not maintained via requirement.txt so it needs a manual step to re-enable awscli.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;pip3 install awscli --upgrade</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h2 id=&quot;Problem-Description&quot;&gt;&lt;a href=&quot;#Problem-Description&quot; class=&quot;headerlink&quot; title=&quot;Problem Description&quot;&gt;&lt;/a&gt;Probl
      
    
    </summary>
    
      <category term="Mac" scheme="http://maxwu.me/categories/Mac/"/>
    
    
      <category term="Mac" scheme="http://maxwu.me/tags/Mac/"/>
    
      <category term="Brew" scheme="http://maxwu.me/tags/Brew/"/>
    
  </entry>
  
  <entry>
    <title>Incrementally measure code coverage</title>
    <link href="http://maxwu.me/2019/06/09/Incrementally-measure-code-coverage/"/>
    <id>http://maxwu.me/2019/06/09/Incrementally-measure-code-coverage/</id>
    <published>2019-06-09T09:42:34.000Z</published>
    <updated>2021-10-24T22:03:14.506Z</updated>
    
    <content type="html"><![CDATA[<p>For new app or repos with a close to ideal level code coverage, the populor code coverage solution on coverage metrics threshold check would be efficient. However, to maintain a legacy or low coverage level repo, it is not eonough to just check coverage percentage on metrics. This post described an idea to check coverage json diff with istanbul-diff on node.js repos.</p><span id="more"></span><h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h2><p>Usually in Jenkins Pipeline or SAAS DevOps infrastructure, the code coverage check is implemented with <code>Cobertura</code> or cloud service <code>Coverage</code>. </p><p>As described in previous posts, here are samples of <code>Coverage</code> service and on-premise <code>Cobertura</code>.</p><p><a href="https://i.imgur.com/gtm74Pr.png"><img src="https://i.imgur.com/gtm74Prm.png" alt="Coverage"></a><br><a href="https://i.imgur.com/YHyhOJ7.png"><img src="https://i.imgur.com/YHyhOJ7t.png" alt="Cobertura"></a></p><p>The coverage check is implemented with metrics and thresholds, in other wors, the score of code coverage on current baseline. This won’t be a problem when the repo has an ideal coverage leve. </p><p>For example, if the threshold is set to 95% on lines, functions and branches thress metrics, when the change breaks the threshold, the coverage check will fail. </p><p>On an legacy repo, this would potentially be a problem with a low coverage level. For an example, if the repo has 45% overall lines coverage. On one of the feature branch, the code change lower down some source code coverage by accidently introduced a wrong condition in Jest. But the feature branch aslo introduced a batch of new source and keep 100% on these new added source filed. Therefore, it is possible to see an increase in <code>Total Coverage</code>. And due to a lower level of <code>Cobertura</code> threshold on existing code, this cannot be discovered by the coverage check at all. The feature branch can be merged to master branch with successful coverage endorsement. </p><p>Above is a real case in coverage overall check with one of my projects. </p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>Since the project mentioned above is a node.js front-end app, the coverage measurement is implemented with Jest coverage. Underneath the jest framework, <a href="https://istanbul.js.org"><code>istanbul</code></a> is the code coverage lib. This triggered me to seek a way to compare the coverage result files from the source branch to target branch.</p><p>The solution could rely on JsonDiff lib to compare the coverage between two branches and fail when there is any nodes on source tree has decrease on coverage unless the leave nodes (file-line, function, branch path) are removed from source branch. </p><p>Here the term <code>leave node</code> depends on which coverage metrics are selected. It could be one or more from lines, functions and branches. The three coverage metrics are supported by istanbul.</p><ul><li><p>The first condition can be satisfied by applying an npm lib <a href="https://github.com/moos/istanbul-diff"><code>istabul-diff</code></a>. Which is based on <code>jsondiffpath</code> lib to compare the increments between source coverage summary and target (existing) one.</p></li><li><p>The second condition would be resolved with traditional way – <code>Artifactory</code>. On Jenkins Pipeline, a goovy closure will be defined to push coverage-summary JSON to artifactory if current <code>BUILD</code> passes and it is on master branch. </p><p>So the artifactory specific PATH will only keep a latest copy of master branch coverage result (in JSON format).</p><p>When Pipeline determines the build is on a feature branch, it will automatically download the master coverage summary from Artifactory and apply istanbul-diff to find if there is any loss on coverage but will accept all the positive (incremental) coverage.</p></li><li><p>To utilize istanbul-diff tool, istanbul reporter <code>json-summary</code> is required. By default Jest would apply parameter <code>[&quot;json&quot;, &quot;lcov&quot;, &quot;text&quot;, &quot;clover&quot;]</code> (refer to <a href="https://jestjs.io/docs/en/configuration#coveragereporters-array-string">Jest Doc</a>)</p><p>So the package.json could be updated as:</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">&quot;jest&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;coverageReporters&quot;</span>: [</span><br><span class="line">      <span class="string">&quot;json&quot;</span>, </span><br><span class="line">      <span class="string">&quot;lcov&quot;</span>, </span><br><span class="line">      <span class="string">&quot;text&quot;</span>, </span><br><span class="line">      <span class="string">&quot;clover&quot;</span>,</span><br><span class="line">      <span class="string">&quot;json-summary&quot;</span></span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="More-topics"><a href="#More-topics" class="headerlink" title="More topics"></a>More topics</h2><p>The author just verified the idea with a rough react sample but haven’t tested the solution with prototype on pipeline yet. Here are actions to fulfill and confirm:</p><ul><li><p>Implement the solution above in an POC branch on pipeline definition file.</p></li><li><p>Take special care to verify when leave nodes are removed, istanbul-diff could accept it not as a failure.</p></li><li><p>When multiple metrics are specified, e.g. both lines and functions, any loss of coverage in one of more of the metrics will fail the final return code.</p></li><li><p>A PR submitted to fix typo in istanbul-diff README Markdown doc, <a href="https://github.com/moos/istanbul-diff/pull/3">https://github.com/moos/istanbul-diff/pull/3</a> </p></li></ul><h2 id="Change-Log"><a href="#Change-Log" class="headerlink" title="Change Log"></a>Change Log</h2><p>Jun 09, 2019: Initial and roughly tested with sample node.js repo. </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;For new app or repos with a close to ideal level code coverage, the populor code coverage solution on coverage metrics threshold check would be efficient. However, to maintain a legacy or low coverage level repo, it is not eonough to just check coverage percentage on metrics. This post described an idea to check coverage json diff with istanbul-diff on node.js repos.&lt;/p&gt;
    
    </summary>
    
      <category term="DevOps" scheme="http://maxwu.me/categories/DevOps/"/>
    
      <category term="Coverage" scheme="http://maxwu.me/categories/DevOps/Coverage/"/>
    
    
      <category term="Istanbul" scheme="http://maxwu.me/tags/Istanbul/"/>
    
      <category term="Coverage" scheme="http://maxwu.me/tags/Coverage/"/>
    
      <category term="DevOps" scheme="http://maxwu.me/tags/DevOps/"/>
    
  </entry>
  
  <entry>
    <title>Convolutional Neural Networks in TensorFlow</title>
    <link href="http://maxwu.me/2019/06/02/Completed-Deeplearning-ai-CNN-in-TensorFlow-A-retro-on-roadmap/"/>
    <id>http://maxwu.me/2019/06/02/Completed-Deeplearning-ai-CNN-in-TensorFlow-A-retro-on-roadmap/</id>
    <published>2019-06-02T02:36:23.000Z</published>
    <updated>2021-10-24T22:03:14.504Z</updated>
    
    <content type="html"><![CDATA[<p>Cheers! Completed the Deeplearning.ai course <strong>Convolutional Neural Networks in TensorFlow</strong>.</p><p><a href="https://imgur.com/Gqldzu2"><img src="https://i.imgur.com/Gqldzu2m.png" alt="Deeplearning-ai-cert-tensorflow-ai-ml-dl"></a></p><p>Following the roadmap, this is the 4th certificates on <a href="https://www.coursera.org">Coursera.org</a> on the Machine Learning path.</p><span id="more"></span><p>Two big application areas are ready to commercialize Machine Learning with more powerful modern CPU or clouds, the computer visioning and NLP. Images and literal words are two main sources to extract features in our minds and so does the ML. </p><table><thead><tr><th>Course</th><th>Keywords</th><th>Completion Date</th><th>School</th></tr></thead><tbody><tr><td><em><strong>Machine Learning</strong></em></td><td>Andrew Ng course as ML 101</td><td>Completed by <code>2017-11-05</code></td><td>Standford University</td></tr><tr><td><em><strong>Introduction to Data Science in Python</strong></em></td><td>An intro to PyNum and Pandas in Data Science</td><td>4 weeks, Completed by <code>2018-04-08</code></td><td>University of Michigan</td></tr><tr><td><em><strong>Convolutional Neural Networks in TensorFlow</strong></em></td><td>Applying CNN with Tensorflow and techniques avoiding overfitting and Transferred learning</td><td>4 weeks, Completed by <code>2019-05-31</code></td><td>deeplearning.ai/coursera</td></tr><tr><td><em><strong>Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning</strong></em></td><td>TansorFlow and Typical ML technoiques and structures for Images</td><td>4 weeks, Completed by <code>2019-05-04</code></td><td>deeplearning.ai/coursera</td></tr><tr><td><strong>Course TBD, Machine Learing in NLP</strong></td><td>Applying ML to NLP, chatbots</td><td>TODO: next step</td><td>TBD</td></tr></tbody></table><p>As on above table, the next bite will be NLP. Let’s move up, buddies!</p><p><a href="https://imgur.com/g9mL59p"><img src="https://i.imgur.com/g9mL59pm.png" alt="ML_Roadmap_draft_1"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Cheers! Completed the Deeplearning.ai course &lt;strong&gt;Convolutional Neural Networks in TensorFlow&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://imgur.com/Gqldzu2&quot;&gt;&lt;img src=&quot;https://i.imgur.com/Gqldzu2m.png&quot; alt=&quot;Deeplearning-ai-cert-tensorflow-ai-ml-dl&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Following the roadmap, this is the 4th certificates on &lt;a href=&quot;https://www.coursera.org&quot;&gt;Coursera.org&lt;/a&gt; on the Machine Learning path.&lt;/p&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://maxwu.me/categories/Machine-Learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Completed Deeplearning.ai TensorFlow Introdution Course</title>
    <link href="http://maxwu.me/2019/05/05/Completed-Deeplearning-ai-TensorFlow-Introdution-Course/"/>
    <id>http://maxwu.me/2019/05/05/Completed-Deeplearning-ai-TensorFlow-Introdution-Course/</id>
    <published>2019-05-05T11:37:15.000Z</published>
    <updated>2021-10-24T22:03:14.504Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><p>Hurray! Completed the Deeplearning.ai course <strong>Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning</strong> and achieved the certificate on coursera!</p><p><a href="https://imgur.com/Gqldzu2"><img src="https://i.imgur.com/Gqldzu2m.png" alt="Deeplearning-ai-cert-tensorflow-intro"></a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;p&gt;Hurray! Completed the Deeplearning.ai course &lt;strong&gt;Introduction to TensorFlow for Artificial Intelligence, Mach
      
    
    </summary>
    
      <category term="Machine Learning" scheme="http://maxwu.me/categories/Machine-Learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Customized domain for github page with hexo</title>
    <link href="http://maxwu.me/2019/05/01/Customized-domain-for-github-page-with-hexo/"/>
    <id>http://maxwu.me/2019/05/01/Customized-domain-for-github-page-with-hexo/</id>
    <published>2019-05-01T10:02:08.000Z</published>
    <updated>2021-10-24T22:03:14.505Z</updated>
    
    <content type="html"><![CDATA[<p>After upgrading hexo and dependencies in local repo package.json, when regenerating the github pages and pushed to remote repo, the customized domain starts to respond 404.</p><p>Check github, the way to add customized domain is to add a CNAME file with each domain in one line. If user tries to manaully configure his/her own domain on github settings tab, a CNAME file will be pegged automatically by github. However, the manually grown CNAME file will be purged in next posting time if hexo is not correctly configured. </p><p>Searching the hexo document, the place to hold this CNAME file is not local repo root folder but the root folder of hexo theme. In My case, it is <code>./themes/next-wuxubj-5.0.2/</code>. If your hexo applies other theme, please change to the corresponding folder name. This way, the CNAME file will be preserved.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;After upgrading hexo and dependencies in local repo package.json, when regenerating the github pages and pushed to remote repo, the custo
      
    
    </summary>
    
      <category term="Github" scheme="http://maxwu.me/categories/Github/"/>
    
    
      <category term="Github" scheme="http://maxwu.me/tags/Github/"/>
    
      <category term="Hexo" scheme="http://maxwu.me/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>Debug dotnet core with LLDB on RHEL Image</title>
    <link href="http://maxwu.me/2019/04/15/Debug-dotnet-core-with-LLDB-on-RHEL-Image/"/>
    <id>http://maxwu.me/2019/04/15/Debug-dotnet-core-with-LLDB-on-RHEL-Image/</id>
    <published>2019-04-15T10:25:42.000Z</published>
    <updated>2021-10-24T22:03:14.505Z</updated>
    
    <content type="html"><![CDATA[<p>This post is based on a quick note on how to create a docker image for openshift/k8s to debug dotnet core app with LLD online in the containter environment.</p><span id="more"></span><h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h2><p>(TBC)</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>It will request a Red Hat developer account to register to RHN when trying to enable <code>rhel-7-server-devtools-rpms</code> RPM repo on Red Hat. However, if it is a docker environment, which is not required to register the docker instance to RHN to add this repo. So the repo could be enabled in Dockerfile. Then the LLDB toolset would be installed to this image.</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># From a customized RHEL dotnet sdk base image</span></span><br><span class="line"><span class="keyword">FROM</span> dotnet/dotnet-<span class="number">21</span>-rhel7</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Set the timezone</span></span><br><span class="line"><span class="keyword">ENV</span> TZ=XXX</span><br><span class="line"> </span><br><span class="line"><span class="keyword">USER</span> root</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum-config-manager --<span class="built_in">enable</span> rhel-7-server-devtools-rpms</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y wget tcpdump vim llvm-toolset-7</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> rm -rf /opt/app-root/.pki</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">USER</span> <span class="number">1001</span></span><br></pre></td></tr></table></figure><h2 id="How-to-debug-dotnet-core-app-with-LLDB"><a href="#How-to-debug-dotnet-core-app-with-LLDB" class="headerlink" title="How to debug dotnet core app with LLDB"></a>How to debug dotnet core app with LLDB</h2><blockquote><p>(TODO):<br>  Push the image to dockerhub and launch more test with AWS environment. </p></blockquote><blockquote><p>Complete this post with more details on how to apply LLDB on memory check and online debug.</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This post is based on a quick note on how to create a docker image for openshift/k8s to debug dotnet core app with LLD online in the containter environment.&lt;/p&gt;
    
    </summary>
    
      <category term="DevOps" scheme="http://maxwu.me/categories/DevOps/"/>
    
      <category term="Docker" scheme="http://maxwu.me/categories/DevOps/Docker/"/>
    
    
      <category term="LLDB" scheme="http://maxwu.me/tags/LLDB/"/>
    
      <category term="DotnetCore" scheme="http://maxwu.me/tags/DotnetCore/"/>
    
      <category term="Docker" scheme="http://maxwu.me/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Acquired AWS Solution Architecture Professional (SAP) and DevOps Professional (DOP) Certificates</title>
    <link href="http://maxwu.me/2018/11/07/Acquired-AWS-Solution-Architecture-and-DevOps-Professional-Certificates/"/>
    <id>http://maxwu.me/2018/11/07/Acquired-AWS-Solution-Architecture-and-DevOps-Professional-Certificates/</id>
    <published>2018-11-07T05:50:29.000Z</published>
    <updated>2021-10-24T22:03:14.503Z</updated>
    
    <content type="html"><![CDATA[<p>When participating the project to migrate Web Service and full pipeline to openshift, it is worthy to continue AWS study to professional level and compare the SAAS hybrid solution to on-premise PAAS with openshift. </p><p>These two certificates were achieved during the above project <code>Evolve</code>.</p><p><a href="https://imgur.com/1KAF74s.png"><img src="https://i.imgur.com/1KAF74sm.png" alt="AWS_DOP"></a><br><a href="https://imgur.com/JyZn4PX.png"><img src="https://i.imgur.com/1KAF74sm.png" alt="AWS_DOP"></a></p><span id="more"></span>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;When participating the project to migrate Web Service and full pipeline to openshift, it is worthy to continue AWS study to professional level and compare the SAAS hybrid solution to on-premise PAAS with openshift. &lt;/p&gt;
&lt;p&gt;These two certificates were achieved during the above project &lt;code&gt;Evolve&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://imgur.com/1KAF74s.png&quot;&gt;&lt;img src=&quot;https://i.imgur.com/1KAF74sm.png&quot; alt=&quot;AWS_DOP&quot;&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://imgur.com/JyZn4PX.png&quot;&gt;&lt;img src=&quot;https://i.imgur.com/1KAF74sm.png&quot; alt=&quot;AWS_DOP&quot;&gt;&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="AWS" scheme="http://maxwu.me/categories/AWS/"/>
    
    
      <category term="AWS" scheme="http://maxwu.me/tags/AWS/"/>
    
      <category term="SAP" scheme="http://maxwu.me/tags/SAP/"/>
    
      <category term="DOP" scheme="http://maxwu.me/tags/DOP/"/>
    
  </entry>
  
  <entry>
    <title>Michigan Data Science with Python Course Achieved</title>
    <link href="http://maxwu.me/2018/04/09/Michigan-Data-Science-with-Python-Course-Achieved/"/>
    <id>http://maxwu.me/2018/04/09/Michigan-Data-Science-with-Python-Course-Achieved/</id>
    <published>2018-04-08T12:04:50.000Z</published>
    <updated>2021-10-24T22:03:14.507Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><p>Completed the 2nd data science course and achieved the certificate on coursera!</p><p><img src="https://i.imgur.com/gE39kX4m.png" alt="Imgur Michigan Data Science with Python Course Cert"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;p&gt;Completed the 2nd data science course and achieved the certificate on coursera!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.
      
    
    </summary>
    
      <category term="Machine Learning" scheme="http://maxwu.me/categories/Machine-Learning/"/>
    
    
      <category term="Python" scheme="http://maxwu.me/tags/Python/"/>
    
      <category term="Data Science" scheme="http://maxwu.me/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>Update Anaconda-Navigator thru command line</title>
    <link href="http://maxwu.me/2018/03/19/Update-Anaconda-Navigator-thru-command-line/"/>
    <id>http://maxwu.me/2018/03/19/Update-Anaconda-Navigator-thru-command-line/</id>
    <published>2018-03-18T20:23:35.000Z</published>
    <updated>2021-10-24T22:03:14.510Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.imgur.com/xFQI6dtl.png" alt="Anaconda-Navigator"></p><span id="more"></span><h2 id="Update-Anaconda-Navigator"><a href="#Update-Anaconda-Navigator" class="headerlink" title="Update Anaconda-Navigator"></a>Update Anaconda-Navigator</h2><p>After the Machine Learning course, I registered Data Science Introduction course (Michigan Univ.) to refresh Python hands. When the pop-up asking about updating anaconda navigator to a new version, I selected “yes” and it just quit current anaconda navigaotr window on Mac. However, Anaconda-Navigator only shut down without any updates. It might be due some permission issue. </p><p>Here is the command line to update Anaconda-Navigator:<br><code>conda update anaconda-navigator</code>.<br>To execute the correct command in cases of pyenv installed to wrap multiple python contexts, you need to select the anaconda pyenv profile and set it to local (or global if intent to). </p><h2 id="Update-Anaconda-Environment"><a href="#Update-Anaconda-Environment" class="headerlink" title="Update Anaconda Environment"></a>Update Anaconda Environment</h2><p>To update anaconda current environment to the latest packages unless dependencies preserve some package versions, the command line is<br><code>conda update conda</code><br>Another way to launch the terminal is to click Anaconda GUI environment column and select “Open Terminal” from the small triangle.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/xFQI6dtl.png&quot; alt=&quot;Anaconda-Navigator&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://maxwu.me/categories/Programming/"/>
    
      <category term="Python" scheme="http://maxwu.me/categories/Programming/Python/"/>
    
    
      <category term="Python" scheme="http://maxwu.me/tags/Python/"/>
    
      <category term="Anaconda" scheme="http://maxwu.me/tags/Anaconda/"/>
    
  </entry>
  
  <entry>
    <title>Stanford A-NG Machine Learning Certificate Achieved</title>
    <link href="http://maxwu.me/2017/11/12/Stanford-A-NG-Machine-Learning-Certificate-Achieved/"/>
    <id>http://maxwu.me/2017/11/12/Stanford-A-NG-Machine-Learning-Certificate-Achieved/</id>
    <published>2017-11-12T09:37:15.000Z</published>
    <updated>2021-10-24T22:03:14.508Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><p>Completed the first machine learning course and achieved the certificate on coursera!</p><p>Rather than warming up mathematics and scripting with new toy of octave(and matlab), it was an experience to enhance time management :_) </p><p><img src="https://i.imgur.com/6WmFoUsm.png" alt="Stanford-Andrew-Ng-ML-Course-Cert"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;p&gt;Completed the first machine learning course and achieved the certificate on coursera!&lt;/p&gt;
&lt;p&gt;Rather than warming 
      
    
    </summary>
    
      <category term="Machine Learning" scheme="http://maxwu.me/categories/Machine-Learning/"/>
    
    
      <category term="Machine Learning" scheme="http://maxwu.me/tags/Machine-Learning/"/>
    
      <category term="Andrew-Ng" scheme="http://maxwu.me/tags/Andrew-Ng/"/>
    
      <category term="Stanford" scheme="http://maxwu.me/tags/Stanford/"/>
    
  </entry>
  
  <entry>
    <title>Greeting Shell script with Picture show and Weathre Forecast</title>
    <link href="http://maxwu.me/2017/09/28/Greeting-Shell-script-with-Picture-show-and-Weathre-Forecast/"/>
    <id>http://maxwu.me/2017/09/28/Greeting-Shell-script-with-Picture-show-and-Weathre-Forecast/</id>
    <published>2017-09-27T12:53:18.000Z</published>
    <updated>2021-10-24T22:03:14.505Z</updated>
    
    <content type="html"><![CDATA[<p>“<strong>iterm2 greeting with weather and image</strong>“ is a short shell made for bash_profil invoke to weather forecast based on GeoIP, a quote of greeting, and, show a random picture from given folder.</p><span id="more"></span><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>It is created to make use of Friday evening and show my daughter’s random picture each time a terminal window is created. After a quick family demo show, I added cli arguments support the next day ㋡</p><h2 id="Features"><a href="#Features" class="headerlink" title="Features"></a>Features</h2><p><a href="https://i.imgur.com/VR53tEE.png"><img src="https://i.imgur.com/VR53tEEm.png" alt="greeting"></a></p><ul><li>Show randmo picture from folder. <ul><li>It follows iTerm2 (on Mac) imgcat extended protocols.</li><li>Picture will be resized to given width in cols or 40 by default</li><li>Picture folder is specified or defaulted to ~/Pictures.</li></ul></li><li>Fetch weathre forecast from wttr.in.</li><li>Adjust format according to current terminal window width.</li></ul><p>Github Link: <a href="https://github.com/maxwu/iterm2_greeting_with_weather_img">https://github.com/maxwu/iterm2_greeting_with_weather_img</a></p><h2 id="Change-Log"><a href="#Change-Log" class="headerlink" title="Change Log"></a>Change Log</h2><p>May28, 2017: Initial post.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;“&lt;strong&gt;iterm2 greeting with weather and image&lt;/strong&gt;“ is a short shell made for bash_profil invoke to weather forecast based on GeoIP, a quote of greeting, and, show a random picture from given folder.&lt;/p&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://maxwu.me/categories/Programming/"/>
    
      <category term="Shell" scheme="http://maxwu.me/categories/Programming/Shell/"/>
    
    
      <category term="iterm2" scheme="http://maxwu.me/tags/iterm2/"/>
    
      <category term="shell" scheme="http://maxwu.me/tags/shell/"/>
    
      <category term="imgcat" scheme="http://maxwu.me/tags/imgcat/"/>
    
  </entry>
  
  <entry>
    <title>Selenium and WebDriver Version Selection</title>
    <link href="http://maxwu.me/2017/08/13/Selenium-and-WebDriver-Version-Selection/"/>
    <id>http://maxwu.me/2017/08/13/Selenium-and-WebDriver-Version-Selection/</id>
    <published>2017-08-12T22:19:09.000Z</published>
    <updated>2021-10-24T22:03:14.507Z</updated>
    
    <content type="html"><![CDATA[<p>This post summarized the versions of browsers and seleniums as well as the dependencies for automation test especially for headless testing. </p><p><img src="https://i.imgur.com/xXsIDBCt.png" alt="[Selenium Pill][https://imgur.com/xXsIDBC]"></p><span id="more"></span><h2 id="Selenium-3"><a href="#Selenium-3" class="headerlink" title="Selenium 3"></a>Selenium 3</h2><p>Current stable version of selenium. From Selenium 3:</p><ul><li>Interacts with Firefox through Mozzila’s Gecko Driver.</li><li>Requests Firefox 47.1.0+ version if choosing Firefox to test (FF v47.0 is not supported).</li><li>Requests Java 8 (which is the oldest official Oracle Java version)</li><li>Works with Edge through EdgeDriver</li><li>Works with IE 9+ through IEDriverServer</li></ul><p>Selenium 3 development plan was announced from 2013. However, the available beta was released by July 2016 and stable Selenium 3 was finally released Oct 2016. Google java lib Guava is also requested. A standalone selenium jar lib is offered from this release.</p><p>Headless browsers:</p><p>The classic way to run selenium based web automation test with browsers will launch browsers GUI windows. Which is slow and requests display settings (on Linux). Webkit based headless browser as Phaontomjs is a better choice when the test is table, or, executed on cloud. </p><p>Recent Firefox and Chrome releases offer headless mode which can fasten the test with less computation cost.</p><table><thead><tr><th>Browser</th><th>Current versions</th><th>Browser version with headless support</th><th>Notes</th></tr></thead><tbody><tr><td>Firefox</td><td>stable:55, beta:56b, dev:57dev</td><td>From v56</td><td>Need FF beta version 56b to support headless mode by set MOZ_HEADLESS=1</td></tr><tr><td>Chrome</td><td>stable:61</td><td>Mac and Linux: from 59, Windows: from 60</td><td>Cli option “”–headless” to run chrome in headless mode (–disable-gpu might be requested on early builds)</td></tr></tbody></table><p>Chrome browser headless mode requests chromedriver version newer than 2.29 due to known update. Current stable chromedriver version is 2.33. For GeckoDriver, v0.19.0 works fine with headless mode firefox.</p><p>Since phantomjs steps down as maintainer by version 2.1.1, there are other lightweight webkit or other engine based headless browser to choose. Visit <a href="https://github.com/dhamaniasad/HeadlessBrowsers">headless browsers</a> for more solutions.</p><h2 id="Selenium-2"><a href="#Selenium-2" class="headerlink" title="Selenium 2"></a>Selenium 2</h2><p>Selenium 2 is the history version to offer a common interface over <a href="https://github.com/SeleniumHQ/selenium/wiki/JsonWireProtocol">JSON wired protocol</a> to interact with web driver executables and through them to browsers. The communication scenario is:</p><p>For IE and Chrome:</p><p>Selenium Language Binding ⇆  Web Driver Executable ⇆  Browser</p><p>For FF without Gecko (without Marionette flavor), headless Phantomjs and HtmlUnit:</p><p>Selenium Language Binding ⇆ Browser</p><p>Since new Firefox utilizes Gecko driver, Selenium 2 works with Firefox version &lt;=47 in stright direct interaction way.</p><p>From Selenium 2, it is called Selenium Web Driver instead of RC.</p><h2 id="Selenium-RC"><a href="#Selenium-RC" class="headerlink" title="Selenium RC"></a>Selenium RC</h2><p>Selenium Remote Control (RC) is history version which interacts with browsers by inject javascript and works as an HTTP proxy. Which requests preconfiguration on security checks for most of modern browsers but provides wide supports with language bindings and most of browsers.</p><p>Selenium Client Driver (with most languages) ⇆ Selenium Server (Jar file) ⇆ Browsers</p><h2 id="Change-Log"><a href="#Change-Log" class="headerlink" title="Change Log"></a>Change Log</h2><p>Nov18, 2017: Add notes on chromedriver version.<br>Aug13, 2017: Initial post draft.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This post summarized the versions of browsers and seleniums as well as the dependencies for automation test especially for headless testing. &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/xXsIDBCt.png&quot; alt=&quot;[Selenium Pill][https://imgur.com/xXsIDBC]&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Automation Test" scheme="http://maxwu.me/categories/Automation-Test/"/>
    
      <category term="Selenium" scheme="http://maxwu.me/categories/Automation-Test/Selenium/"/>
    
    
      <category term="Automation Test" scheme="http://maxwu.me/tags/Automation-Test/"/>
    
      <category term="Selenium" scheme="http://maxwu.me/tags/Selenium/"/>
    
      <category term="Headless" scheme="http://maxwu.me/tags/Headless/"/>
    
      <category term="Firefox" scheme="http://maxwu.me/tags/Firefox/"/>
    
      <category term="Chrome" scheme="http://maxwu.me/tags/Chrome/"/>
    
  </entry>
  
  <entry>
    <title>Capture Existing Selenium WebDriver Session</title>
    <link href="http://maxwu.me/2017/08/06/Capture-Existing-Selenium-WebDriver-Session/"/>
    <id>http://maxwu.me/2017/08/06/Capture-Existing-Selenium-WebDriver-Session/</id>
    <published>2017-08-06T10:43:07.000Z</published>
    <updated>2021-10-24T22:03:14.504Z</updated>
    
    <content type="html"><![CDATA[<p>Notes on how to intervene an existing selenium web driver session with impelementation and tests.</p><span id="more"></span><h2 id="Problem-to-Solve"><a href="#Problem-to-Solve" class="headerlink" title="Problem to Solve"></a>Problem to Solve</h2><p>As a software engineer in automation test, sometimes it is the most reasonable method to capture the existing selenium web driver session and intervene with customized action steps. Especially with the commercial toolkit or homemade testing utility but source is not open at the meantime. </p><p>In my case, the toolkit is not able to fill up one of the authentication page. However, it offers a keyword to pause until a manual action to input user crediential. Current solution is to monitor the stdout with bash shell, when the typical log of “<a href="http://localhost:XXXX&quot;">http://localhost:XXXX&quot;</a> shows up, use the selenium commander URL to capture the existing selenium session. There is still a parameter of session ID missing. This can be solved by an JSON wired protocol end point, “/sessions”. Usually toolkit implements singleton on seleenium driver language binding. Query the end point of “/sessions” will return the session ID between web driver executable and the browser.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><h3 id="Find-Existing-Session-ID"><a href="#Find-Existing-Session-ID" class="headerlink" title="Find Existing Session ID"></a>Find Existing Session ID</h3><p>As mentioned in above, the communication between Selenium Development Language bindings and WebDriver executables is the JSON wired protocol. </p><p><a href="https://github.com/SeleniumHQ/selenium/wiki/JsonWireProtocol#sessions">https://github.com/SeleniumHQ/selenium/wiki/JsonWireProtocol#sessions</a></p><p>Unfortunately this end point is not implemented with Selenium Java or Python binding. It could be soloved by a new created wrapper function to query existing sessions.</p><p>Generally automation test toolkit desktop version implements singleton on selenium binding instance and keep one session. So the query above will return one session in JSON. The solution is to add code parsing the return value and extract the session ID.</p><p>For example, if the selenium based toolkit generates stdout or logs as:</p><p>  <code>http://localhost:6064</code> </p><p>The session can be queried by URL in browser with the end point:</p><p>  <code>http://localhost:6064/sessions</code></p><!---FIXME: need to download the original image from qiniu.![JSON Return Value](http://oei21r8n1.bkt.clouddn.com/Query_Selenium_Sessions.png?imageView/2/w/400/q/100)--><p>(Update Aug 08, 2017) The sample code to query session information. The codesnap only return the first session ID and capabilities in tuple. Production code shall take care of situation when there are multiple sessions as well. </p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># return tupple of session ID and capability dict.</span></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_session_id_and_cap</span>(<span class="params">command_executor=<span class="literal">None</span></span>):</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> command_executor:</span><br><span class="line">   <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># requests respects environment variables on proxy and does not bypass localhost.</span></span><br><span class="line">    <span class="comment"># It seems the new post IETF draft catches eyes to solve such issues,</span></span><br><span class="line">    <span class="comment"># https://tools.ietf.org/html/draft-west-let-localhost-be-localhost-04</span></span><br><span class="line">    os.environ[<span class="string">&#x27;NO_PROXY&#x27;</span>] = <span class="string">&#x27;localhost&#x27;</span></span><br><span class="line"></span><br><span class="line">    url = command_executor + <span class="string">&#x27;/sessions&#x27;</span></span><br><span class="line">    resp = requests.get(url=url)</span><br><span class="line">    data = json.loads(resp.text)</span><br><span class="line">    <span class="keyword">if</span> data[<span class="string">&#x27;value&#x27;</span>]:</span><br><span class="line">        <span class="keyword">return</span> data[<span class="string">&#x27;value&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;id&#x27;</span>], data[<span class="string">&#x27;value&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;capabilities&#x27;</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>(End of Aug 08, 2017 Update)</p><h3 id="Capture-Existing-Selenium-Session"><a href="#Capture-Existing-Selenium-Session" class="headerlink" title="Capture Existing Selenium Session"></a>Capture Existing Selenium Session</h3><p>With an effective session ID and executing commander URL, the captured web driver class overwrites start_session method. Property “w3c” is assigned for Web Element Find method groups.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CapturedDriver</span>(<span class="params">WebDriver</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; CapturedDriver.doctest_visit_github()</span></span><br><span class="line"><span class="string">    PASS</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">                 command_executor=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 desired_capabilities=&#123;&#125;,</span></span></span><br><span class="line"><span class="params"><span class="function">                 browser_profile=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 proxy=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 keep_alive=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 session_id=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 w3c=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CapturedDriver, self).__init__(command_executor, desired_capabilities, browser_profile, proxy, keep_alive)</span><br><span class="line">        self.session_id = session_id</span><br><span class="line">        self.w3c = w3c</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_session</span>(<span class="params">self, desired_capabilities, browser_profile</span>):</span></span><br><span class="line">        self.capabilities = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">doctest_visit_github</span>():</span></span><br><span class="line">        d = wd.Firefox()</span><br><span class="line">        d.get(<span class="string">&#x27;http://github.com&#x27;</span>)</span><br><span class="line">        <span class="comment"># &quot;The world&#x27;s leading software development platform · GitHub&quot;</span></span><br><span class="line">        title1 = d.title</span><br><span class="line">        d2 = CapturedDriver(command_executor=d.command_executor, session_id=d.session_id, w3c=d.w3c)</span><br><span class="line">        title2 = d2.title</span><br><span class="line">        <span class="keyword">if</span> title1 == title2:</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&quot;PASS&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&quot;driver title is %s, captured driver title is %s&quot;</span> % (title1, title2)</span><br><span class="line">        d.quit()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> doctest</span><br><span class="line">    doctest.testmod()</span><br></pre></td></tr></table></figure><p>The unit test is implemented with doctest as a fast way for experiment codes.</p><p>The source code is shared at <a href="https://github.com/maxwu/selenium-behave-box/blob/master/src/captured_driver/captured_driver.py">Github Folder</a> now. Java binding solution is still under construction. After that, a separate Github project will be created to maintain this solution together with monitoring bash shell. </p><h2 id="Test-The-Solution"><a href="#Test-The-Solution" class="headerlink" title="Test The Solution"></a>Test The Solution</h2><p>To tes the solution, open a selenium session and extract the session ID and commander URL. For a quick test, the existing github project <a href="https://github.com/maxwu/cucumber-java-toy">cucumber-java-toy</a> is used. The code is as below:</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">webDriver1</span><span class="params">()</span></span>&#123;</span><br><span class="line">    githubPage = <span class="keyword">new</span> GithubPage(driver, <span class="string">&quot;maxwu&quot;</span>);</span><br><span class="line">    List&lt;String&gt; followings = githubPage.getFollowingList();</span><br><span class="line">    followings.stream().forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">    URL driverUrl = ((HttpCommandExecutor)(((RemoteWebDriver) driver).getCommandExecutor())).getAddressOfRemoteServer();</span><br><span class="line">    String sessionId = ((RemoteWebDriver) driver).getSessionId().toString();</span><br><span class="line">    System.out.println(<span class="string">&quot;URL=&quot;</span> + driverUrl + <span class="string">&quot; ID=&quot;</span> + sessionId);</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">&quot;Old Title=&quot;</span> + driver.getTitle());</span><br><span class="line"></span><br><span class="line">    pause();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>When the commander URL and session ID are available, the quick test could be performed with below Python snap.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> captured_driver.captured_driver <span class="keyword">import</span> CapturedDriver</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># For temp test</span></span><br><span class="line">    <span class="comment"># d = CapturedDriver(command_executor=&#x27;http://127.0.0.1:4444/wd/hub&#x27;, session_id=&#x27;&#x27;)</span></span><br><span class="line">    d = CapturedDriver(command_executor=<span class="string">&#x27;http://localhost:6064 &#x27;</span>, session_id=<span class="string">&#x27;49075f494d1add687ab74f1cb95f0314&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;Captured Session Title is %s&quot;</span> % d.title</span><br><span class="line">    explore = d.find_element_by_link_text(<span class="string">&quot;Explore&quot;</span>)</span><br><span class="line">    explore.click()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;Captured Session Title changes to %s&quot;</span> % d.title</span><br><span class="line">    d.back()</span><br></pre></td></tr></table></figure><p>Successful output of test code shall be:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Captured Session Title is maxwu (Max WU) / Following · GitHub</span><br><span class="line">Captured Session Title changes to Explore · GitHub</span><br></pre></td></tr></table></figure><p>Since browser is not running in headless mode, the page transition and backward movement action can also be visual checked that the captured web driver works fine and either driver can quit the session, which leads to a termination on web driver executable process, too.</p><h2 id="Future-Works"><a href="#Future-Works" class="headerlink" title="Future Works"></a>Future Works</h2><ul><li><p>Add query on “/sessions” end point for Selenium Java Binding.<br>Prototype passed test. (TODO: update github and maintain in separate repo).</p></li><li><p>Implement Captured Web Driver with Selenium Java Binding.</p></li><li><p>It works fine with GeckoDriver for Firefox on both Mac and Windows. However, IEDriverServer throws 404 error while performing “find*” API calls. </p><p>It finally reject the 2nd connection with Selenium Python binding. In the meantime, title/url property query through the JSON wired protocol works well.</p></li></ul><h2 id="Change-Log"><a href="#Change-Log" class="headerlink" title="Change Log"></a>Change Log</h2><p>Aug 06, 2017: Initial post as a quick note on captured session with selenium web driver.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Notes on how to intervene an existing selenium web driver session with impelementation and tests.&lt;/p&gt;
    
    </summary>
    
      <category term="Automation Test" scheme="http://maxwu.me/categories/Automation-Test/"/>
    
      <category term="Selenium" scheme="http://maxwu.me/categories/Automation-Test/Selenium/"/>
    
    
      <category term="Concrete-level-tag" scheme="http://maxwu.me/tags/Concrete-level-tag/"/>
    
      <category term="Automation Test" scheme="http://maxwu.me/tags/Automation-Test/"/>
    
      <category term="Selenium" scheme="http://maxwu.me/tags/Selenium/"/>
    
  </entry>
  
  <entry>
    <title>A Dip on Performance Testing</title>
    <link href="http://maxwu.me/2017/07/25/Briefing-on-Performance-Testing/"/>
    <id>http://maxwu.me/2017/07/25/Briefing-on-Performance-Testing/</id>
    <published>2017-07-25T11:03:57.000Z</published>
    <updated>2021-10-24T22:03:14.504Z</updated>
    
    <content type="html"><![CDATA[<p>There are many sources over internet to describe performance testing. But most are not for new comer to kick start when people have tasks right in hands seeking for an jump start point to enter. This post targets to provide a glace of it with practical hints and introduce some simple methods and toolkits. (In progress)<br><span id="more"></span></p><h2 id="Types-of-Performance-Testing"><a href="#Types-of-Performance-Testing" class="headerlink" title="Types of Performance Testing"></a>Types of Performance Testing</h2><p>There are two kinds of performance testing mostly seen in practices. </p><h3 id="Quantitive-Measurement"><a href="#Quantitive-Measurement" class="headerlink" title="Quantitive Measurement"></a>Quantitive Measurement</h3><p>One type is to seek a quantitive measurement on software + hardware(cloud/infrastructure environment). Usually the practice is with automation toolkits to simulate concurrent transactions (for OLTP) or streams (for transmission systems). The key factors would be sorted into categories and critical factors will be figured during the test. </p><p><a href="http://www.maxwu.me/2017/02/26/Apache-ab-and-gnuplot-to-generate-benchmark-test-chart/">An example of gnuplot chart on performance testing with apache ab toolkit</a></p><p><img src="https://i.imgur.com/4UtYp66m.png" alt="[benchmark performance test chart][https://imgur.com/4UtYp66]"></p><p>According to different quantative measurement perpectives, the measurements are also named to different performance test kinds. Among them, <strong>Load Test</strong> and <strong>Capacity Test</strong> are often planned on verticle and horizontal views.</p><p>Load Test is executed against service level agreement on temporal and spcial factors. Industry practice, especially in telecommunication, the measurement is on statistical results according to standard definition of MTBF(Mean Time Between Failure) and MTTF(Mean Time To Failure). Here MTBF is the sum of MTTF and MTTR (Mean Time To Repair).</p><p>Capacity Test figures out which dimension is critical for scaling. Horizontal as scaling-out or Vertical as scaling-up.</p><h3 id="Stressing-Test"><a href="#Stressing-Test" class="headerlink" title="Stressing Test"></a>Stressing Test</h3><p>Another type of performance test is to stress the software system into an predesigned extreme situation and verify if the availability and IO/Transaction rate can still satisfy the criteria of such circumstance. </p><p>For example, I made a dynamic lib with toolchain to load into embedded Linux card to consume a certain portion (read from cli) of CPU time on the designated core. If the portion is 70%, the test will show system behavior with one core 70% busy as background traffic effects. The result is satifying or not compliant with estimated criteria per requirement key checkpoints by agile team. </p><p>Another example is to generate 8 TCP streams with IPerf tool and test if the system can still holds the acceptance success rate. </p><p>Innovation of testing methodologies could save the cost and time by introducing new techniques to stress system. One case is that I used to set Linux IP Filter to drop 50% packets from some source and verify if the fault handling is still correct. </p><h2 id="Toolkits-and-Tips-to-Implement-Performance-Testing"><a href="#Toolkits-and-Tips-to-Implement-Performance-Testing" class="headerlink" title="Toolkits and Tips to Implement Performance Testing"></a>Toolkits and Tips to Implement Performance Testing</h2><h3 id="Simulate-the-Background-Load"><a href="#Simulate-the-Background-Load" class="headerlink" title="Simulate the Background Load"></a>Simulate the Background Load</h3><p>Background load here refers to the prerequisites to kick off stressing test. It usually includes one of below item or a combination of picked up factors.</p><h4 id="CPU-load"><a href="#CPU-load" class="headerlink" title="CPU load"></a>CPU load</h4><p>(per core or for specific cores)</p><h4 id="Memory-Pressure"><a href="#Memory-Pressure" class="headerlink" title="Memory Pressure"></a>Memory Pressure</h4><p>(Pay attention to libc-rt malloc and overcommitment.)</p><h4 id="Traffics-w-or-w-o-stream-packet-dropping-rate"><a href="#Traffics-w-or-w-o-stream-packet-dropping-rate" class="headerlink" title="Traffics (w/ or w/o stream/packet dropping rate)"></a>Traffics (w/ or w/o stream/packet dropping rate)</h4><p>(Stream: shape, rate, ToS/QoS, Jumbo packets, Back-to-back)</p><p>(IP Filter based packet drop rate)</p><p>(SQL transaction drop rate)</p><p>(Load Balance Policy based failure rate)</p><p>(Other failure rate)</p><p>(TBC)</p><h4 id="Persistance-status-disk-occupation-rate-disk-IO-pressure"><a href="#Persistance-status-disk-occupation-rate-disk-IO-pressure" class="headerlink" title="Persistance status (disk occupation rate, disk IO pressure)"></a>Persistance status (disk occupation rate, disk IO pressure)</h4><p>(IOwait measurement, simulation)</p><p>(TBC)</p><h2 id="Performance-Issues-Sharing"><a href="#Performance-Issues-Sharing" class="headerlink" title="Performance Issues Sharing"></a>Performance Issues Sharing</h2><p>(Experiences of solving performance issues)</p><p>(TBC)</p><h2 id="Change-Log"><a href="#Change-Log" class="headerlink" title="Change Log"></a>Change Log</h2><p>Jul26, 2017: Initial post draft.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;There are many sources over internet to describe performance testing. But most are not for new comer to kick start when people have tasks right in hands seeking for an jump start point to enter. This post targets to provide a glace of it with practical hints and introduce some simple methods and toolkits. (In progress)&lt;br&gt;
    
    </summary>
    
      <category term="Automation Test" scheme="http://maxwu.me/categories/Automation-Test/"/>
    
      <category term="Performance Test" scheme="http://maxwu.me/categories/Automation-Test/Performance-Test/"/>
    
    
      <category term="Performance Testing" scheme="http://maxwu.me/tags/Performance-Testing/"/>
    
      <category term="Stressing Testing" scheme="http://maxwu.me/tags/Stressing-Testing/"/>
    
  </entry>
  
  <entry>
    <title>Lessons and Thoughts on Agile and Test Automation Approaches</title>
    <link href="http://maxwu.me/2017/06/09/Lessons-and-Thoughts-on-Agile-and-Test-Automation-Approaches/"/>
    <id>http://maxwu.me/2017/06/09/Lessons-and-Thoughts-on-Agile-and-Test-Automation-Approaches/</id>
    <published>2017-06-09T04:45:23.000Z</published>
    <updated>2021-10-24T22:03:14.507Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://imgur.com/c30BjQG"><img src="https://i.imgur.com/c30BjQGm.png" alt="Lake Zixia"></a></p><blockquote><p>The picture was taken for Zixia (Purple Light) Lake in famous Mt. Zijin of Nanjing (Nanking) city by my previous colleague. When we talk about migration to agile and automation test, it is rather to create a harmony with history assets and moderm methodology like to vitalize traditional building in morden metropolis with inner high-tech structural works, rather than a revolution on exteriority.<br><span id="more"></span></p></blockquote><p>($\color{blue}{Lively\ Updating}$) This post is based on the original Chinese blog articles and most parts are rewritten. I would keep on retrospectives and update it with new ideas periodically.</p><h2 id="Brief"><a href="#Brief" class="headerlink" title="Brief"></a>Brief</h2><p>A better title could be “Myths in Test Automation – a view from engineer”. However, not to scare readers, we just keep it lively maintained as issue list with contourmeasures and thoughts.</p><h2 id="4-versions-of-engineering-team-with-in-testing"><a href="#4-versions-of-engineering-team-with-in-testing" class="headerlink" title="4 versions of engineering team with/in testing"></a>4 versions of engineering team with/in testing</h2><p><strong>Version 1: Streamline Workers in Testing</strong></p><p><strong>Version 2: Agile Testing</strong></p><p><strong>Version 3: Role changed from tester to QA</strong></p><p><strong>Version 4: Full Stack Testing Team</strong></p><p>Here Full Stack is a term to reflect an end-to-end view from QA perspective rather than just testing.</p><h2 id="Where-we-are-–-The-shape-of-test-automation"><a href="#Where-we-are-–-The-shape-of-test-automation" class="headerlink" title="Where we are – The shape of test automation"></a>Where we are – The shape of test automation</h2><p>At first, this section describes from a high level view on how to reinforce test automation. </p><h3 id="Test-Pyramid-–-Ideal-Agile-Testing"><a href="#Test-Pyramid-–-Ideal-Agile-Testing" class="headerlink" title="Test Pyramid – Ideal Agile Testing"></a>Test Pyramid – Ideal Agile Testing</h3><p>The chart of Pyramid model is from <a href="https://martinfowler.com/bliki/TestPyramid.html">Martin Fowler</a>. Test Pyramid is from <a href="http://www.mountaingoatsoftware.com/">Mkie Cohn</a>. </p><blockquote><p>The test pyramid is a concept developed by Mike Cohn, described in his book Succeeding with Agile. Its essential point is that you should have many more low-level unit tests than high level end-to-end tests running through a GUI.</p></blockquote><div><a href="https://martinfowler.com/bliki/TestPyramid.html" id="richardson_restful_maturity_mdel" align=left><br>     <img src="https://martinfowler.com/bliki/images/testPyramid/test-pyramid.png"  width=240><br></a><br><a href="https://watirmelon.blog/2012/01/31/introducing-the-software-testing-ice-cream-cone/" id="richardson_restful_maturity_mdel" align=center><br>     <img src="https://watirmelon.files.wordpress.com/2012/01/idealautomatedtestingpyramid.png"  width=240><br></a><br></div><p>Like bringing data as close to code as possible, the test shall be as close to code as possible. The distance of data and code increases the cost to warm data and rotate memory pages with cache line. The distance between test and code, in both space and time dimensions, could be regarded as a sign of cost of organization focus switch. </p><p><a href="https://watirmelon.blog/2012/01/31/introducing-the-software-testing-ice-cream-cone/">Alister Scott</a> added manual test on top of the pyramid. </p><ul><li><p>Fast iteration does not offer testing team a long time to perform more manual tests and the automated CI/CD becomes the fundamentals of agile to shorten the feedback cycle towards an autonomous learning organization. Even though, there are spaces for manual scenario based testing and exploring as an indispensable part of Agile Development cycle. It is true that the manual test sessions are a bit further to codes and extend a feedback cycle, but it is important to inspect from user scenario view and utilze human initiatives to qualify the software crafts and process.</p></li><li><p>Another take-away is the ability of test works to be <strong>reused</strong>. The lower it shows in above chart, the better adaptability it could have. </p><ul><li><p>UT is closest to code and will be maintained with code changes together with CI protection. The gap is counted by minutes. With <strong>Lava Light</strong> and CI, UT is consistent with code within 20min for most cases.</p></li><li><p>API and component interfaces have a middle level re-useability. Most of the test works are stable by a well reganized design style. If there are issues that APIs change frequently according to busniess, it is a smell of Architecture Refactor. The original design does not expect the busniess evolution model.</p></li><li><p>For UI layer and manual scenario tests, it is costing to maintain through releases because there are presentation of business and expected to change accordingly. With technologies like Page Object and a good automation framework, the costs could be mitigated sometimes. </p></li></ul></li></ul><h3 id="Icecream-Cone-Anti-Pattern-–-The-Reality"><a href="#Icecream-Cone-Anti-Pattern-–-The-Reality" class="headerlink" title="Icecream Cone Anti-Pattern – The Reality"></a>Icecream Cone Anti-Pattern – The Reality</h3><p><a href="https://watirmelon.blog/2012/01/31/introducing-the-software-testing-ice-cream-cone/">Alister Scott</a> also pointed an <strong>“Icecream Cone Anti-Pattern”</strong> to describe the reality of testing industry.  </p><p><a href="https://watirmelon.blog/2012/01/31/introducing-the-software-testing-ice-cream-cone/" id="richardson_restful_maturity_mdel" align=left><br>     <img src="https://watirmelon.files.wordpress.com/2012/01/softwaretestingicecreamconeantipattern.png"  width=220><br></a></p><p>Where the organizations have history assets or in an intermedium position to grow skilled engineers in testing, the most evident activities are still manual tests. </p><p>One possible reason is with culture building, as <strong><a href="https://en.wikipedia.org/wiki/Conway%27s_law">Conway’s Law</a></strong> points out, the organization way of evaluating co-workers will come out with the output of software processes. If engineers work in an atmosphere that the bug numbers are a key to evaluate themselves, the manual test, with its time and resource consumption will be an asset, or, a debt, of the orgnazation. </p><p>Another possible reason is also on culture that developers don’t have enough encourage or time to protect works with Unit Test. On the contrast, writing unit tests will influence developers to think about how peers are using that part of code and the structure will be designed to adapt a better decoupling philosophy and a better testability (the level of how the program is friendly to test, and then friendly to refactor).</p><h3 id="Cupcake-Anti-Pattern-–-Reality-of-Agile-Testing"><a href="#Cupcake-Anti-Pattern-–-Reality-of-Agile-Testing" class="headerlink" title="Cupcake Anti-Pattern – Reality of Agile Testing"></a>Cupcake Anti-Pattern – Reality of Agile Testing</h3><p>Software Testing <strong>Cupcafe Anti-Pattern</strong> is a model by <a href="https://www.thoughtworks.com/profiles/fabio-pereira">Fabio Pereira, Thoughworks</a> to describe what agile turns out to be in most organizations.</p><p><a href="https://www.thoughtworks.com/insights/blog/introducing-software-testing-cupcake-anti-pattern" align=left><br>     <img src="https://insights-images.thoughtworks.com/fabiocupcakenew1_0_04444aff9e8be210d16a68f29a20fe7a.png"  width=300><br></a></p><p>The most siganificant take-away from this model is the isolation smell. It works partially as a mini-waterfall model that groups of team members make duplicated coverage. It usually happens when there is a separate automation testing team and an existing asset of “manual” test group to keep current business running.</p><h3 id="Rugby-Model-–-Time-to-propose-a-theory-to-experiment"><a href="#Rugby-Model-–-Time-to-propose-a-theory-to-experiment" class="headerlink" title="Rugby Model – Time to propose a theory to experiment"></a>Rugby Model – Time to propose a theory to experiment</h3><p><a href="https://imgur.com/jawzSgF"><img src="https://i.imgur.com/jawzSgFm.png" alt="Rugby Test Model"></a></p><p>Focus on the middle layer instead of Unit Test. During the Agile Migration, pay most attention on API testing. For example, RESTful API testing can be extended to scenario test and create conditions and checkpoints for sceanrio level inspection. The RESTful API level automation testing can also provide a primary data analysis on which part is the most urgent section to protect with Unit Test.</p><p>It is not a fresh new concept. The term <a href="https://martinfowler.com/bliki/SubcutaneousTest.html">Subcutaneous Test</a> covers the similar way on a pseudo end-to-end test but avoid the UI complexity (complexity is usually a singal of heavy design and indicator of high risk on test maintenance).</p><h2 id="Thoughts-on-common-practice-issues-in-Automation-Test"><a href="#Thoughts-on-common-practice-issues-in-Automation-Test" class="headerlink" title="Thoughts on common practice issues in Automation Test"></a>Thoughts on common practice issues in Automation Test</h2><h3 id="Tools-matter-–-Yes"><a href="#Tools-matter-–-Yes" class="headerlink" title="Tools matter – Yes"></a>Tools matter – Yes</h3><p>Tools are not only tools in a transverse movement, but also a way of cultrual idea exchange and influence on way of works.</p><p><img src="http://www.avsforum.com/forum/imagehosting/31795589cbcbb28a21.jpg" alt=""></p><p>SW Dev Frameworks are tools and ROR almost defined the practice standard for a narrowed scope of RESTful. Without JUnit, XUnit, the basic Unit Test concepts would NOT become as popular as they are now. Without <strong>120 fps</strong> technology, movie “Billy Lynn’s Halftime Walk” could hardly bring audience the experience on what <strong>Ang Lee</strong> is exactly designed. A home-made toolkit or customized automation framework is a way to influence crew, too.</p><p>It is an effecient way to communicate with whole team on objectives, process, learning topics. As an old saying in Lucent, tools are ways to train people by supporting ourselves. </p><h3 id="Mixed-Coding-and-Test-Skills-–-Yes"><a href="#Mixed-Coding-and-Test-Skills-–-Yes" class="headerlink" title="Mixed Coding and Test Skills – Yes"></a>Mixed Coding and Test Skills – Yes</h3><p>This topic is still debating upon situations. This is the mostly heard challenge when quite a number of organizations do “SWOT” analysis towards test automation. However, the observation is that interruption matters more. Below is based on the close observation and discussions with test professionals.</p><p>When I am doing a manual test to GA a SW release sometimes, I don’t expect an out-of-observation-scope interruption to system which drive me have to start over. It costs energy for human beings to concentrate for a while no matter what we are doing. Testing is somehow a lonely work without in-time feedbacks as in games. To predict the logic branches and weak points consume more than it looks like.</p><p>On the other side, coding skills are still inevitably critical to implement a stably reproducable test smoothly. Programming language expertise is vital not only on exploring and implementing tests, but also to form a predictable but effective ways to design the tests. Relationship between factors in space, time and logics are expected natrual to engineers in automaiton test role. Therefore, the tests, CI and CD can provide confidence to joint agile team. I keep an average of 1.5 issues discovered per working day in first two weeks of manual testing phase. The credit gives to development experiences. Which helps me to think in a systematic structure and perform test in well organized space as a journey with several dimensions.</p><p>This way, we say that <strong>testing is the way to use techniques to mitigate uncertaincy</strong>. </p><h3 id="Tree-vs-Forest-–-Both"><a href="#Tree-vs-Forest-–-Both" class="headerlink" title="Tree vs. Forest – Both"></a>Tree vs. Forest – Both</h3><p>As a software engineer, I do have happy jouneys with occassional automation test in early years. Which are also called one time tools. The utilities were created to resolve a certain type of testings in such situations:</p><ul><li><p>Some tests are not able to complete manually. Constrains on space and time might be not easily to satisfy with manual actions.</p><ul><li><p>One example is burst Wi-Fi connection and disconnection to a home gateway. </p><p>  When I first realized an issue was with memory fragmentation, the test case in my mind is to call volunteers from my team together with all Android tablets, mobiles, laptops we can borrow and carry to lab and make a series of burst join/quit. It is true and I really did it once .I still keep the photo that a group of people are doing Wi-Fi connecting test together, for memory, for the sweats and cheers). </p><p>  But after we reproduced the issue and successfully match the symptom as filed team suffered, it was not feasible to stay with the so called crowd action to qualify the patch-up component integration. Therefore an urgent request of tool to stably reproduce this issue is created. An one time tool could turn the unknown uncertaincy to known uncertaincy and release efforts.</p></li></ul></li></ul><ul><li><p>Some test case request special skill to reproduce.</p><ul><li>It is like that some piano songs can only play with computer because the pace is too quick human fingers can hardly move this way.<ul><li>An example is a race condition with home gateway GUI, TR69 management interface. It exhausts patience to reproduce it and record every execution sequences to table. Some of the pattern is sophisticated and ambiguous if we only tell from the text description. </li></ul></li></ul></li><li><p>To explore more during the test. </p><ul><li>Tools like JBroFuzz provides precompiled fuzzers to offer randomization for different purpose. If the exploring is only on the space dimension of data feeding, as changing from a ascii-lower set to base64 set, or explore SQL-injection set for MySQL DB, it is time to introduce one time tools.</li><li>Knowing there is an issue, but not sure how big the impacted scope is, or, what exact the trigger threshold is.</li></ul></li></ul><p>One-time automation test is like trees. This is an utilization of tools to achieve above expectations. It is happy and cheerful. However, this is not the same concept of test automation.   </p><p>[Pub-2, 2019-05-19]: Update the image links]</p><p>[Pub-1, 2017-06-09]: Since most parts are rewritten or revised, the release date of this post is changed to recent day]</p><p>[draft-2, 2017-06-02]: Add agile test models, bring up Rugby model]</p><p>[draft-1, 2017-01-25]: Initial draft.</p><blockquote><p>Some of the drafts are not on original Chinese version post, so a special date 12/31 will be used to track the global version.</p></blockquote><p>[EOF]</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://imgur.com/c30BjQG&quot;&gt;&lt;img src=&quot;https://i.imgur.com/c30BjQGm.png&quot; alt=&quot;Lake Zixia&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The picture was taken for Zixia (Purple Light) Lake in famous Mt. Zijin of Nanjing (Nanking) city by my previous colleague. When we talk about migration to agile and automation test, it is rather to create a harmony with history assets and moderm methodology like to vitalize traditional building in morden metropolis with inner high-tech structural works, rather than a revolution on exteriority.&lt;br&gt;
    
    </summary>
    
      <category term="Automation Test" scheme="http://maxwu.me/categories/Automation-Test/"/>
    
      <category term="Agile" scheme="http://maxwu.me/categories/Automation-Test/Agile/"/>
    
    
      <category term="Agile" scheme="http://maxwu.me/tags/Agile/"/>
    
      <category term="Test Automation" scheme="http://maxwu.me/tags/Test-Automation/"/>
    
  </entry>
  
  <entry>
    <title>Thoughts on RESTful API Design and Testing</title>
    <link href="http://maxwu.me/2017/05/20/Thoughts-on-RESTful-API-Design-and-Testing/"/>
    <id>http://maxwu.me/2017/05/20/Thoughts-on-RESTful-API-Design-and-Testing/</id>
    <published>2017-05-20T09:27:33.000Z</published>
    <updated>2021-10-24T22:03:14.509Z</updated>
    
    <content type="html"><![CDATA[<p>This article is inspired by another post described the disapproving on current common misunderstanding among concepts of RESTful, CRUD, Safety, Security and Idempotency.<br><a href="https://imgur.com/tS7bZ9i">![RESTful Img][https://i.imgur.com/tS7bZ9im.png]</a><br>This post targets to rephase RESTful concept and describes common check points against RESTful API architecture test during Software Design Review.As practical samples, Jenkins API and CircleCI/TravisCI API will be analyzed, tested and evaluated.<br><span id="more"></span></p><h2 id="1-RESTful-Style-Design"><a href="#1-RESTful-Style-Design" class="headerlink" title="1 RESTful Style Design"></a>1 RESTful Style Design</h2><h3 id="1-1-RESTful-Maturity-Model-and-the-Background"><a href="#1-1-RESTful-Maturity-Model-and-the-Background" class="headerlink" title="1.1 RESTful Maturity Model and the Background"></a>1.1 RESTful Maturity Model and the Background</h3><p>$\mathsf{\color{olive}{✐\ RESTful}}$: <strong>REpresentational State Transfer</strong>, by Roy Thomas Fielding <a href="https://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm" title="Architectural Styles and the Design of Network-based Software Architectures">Phd Dessertation</a>, 2000.</p><p><a href="https://en.wikipedia.org/wiki/Representational_state_transfer" title="RESTful Wiki">RESTful</a> is a style of architecture. It is also called <strong>Resource Oriented Architecture (ROA)</strong> Which defines a group of restrictions for common architecturing practices as a meta architecture. RESTful compliant deliveries take the conventions of restrictions to build self-describable (semantic) network all together. </p><p>Approaching with RESTful is like a ceremony to take a breakfast coffee ☕ in the morning ☀ to start the day with greeting and smile to people in community while exchaning news, sports and weather. The network is community which Apps and Services live within and people in ceremony are the nodes compliant to RESTful. Those common restrictions release the stress of life and offer people dimensions of freedom to move up (evolve, or, live with happiness) and exchange information.</p><p>Traditionally a common style of API service architecture focused on operations. For example, the client creates the form and fulfills it with operation code, data and adjacent properties (session, auth) then sends it to server and expect a state transition on server. It creates a coupling between client and server, hardly to keep URL consistent in system evolution, and, operation focused design brings side effects as stateful constrain, cache application issue.</p><p>While RESTful service is designed against resources. In short, <strong>URI is only designed for resources</strong>, Aka. <strong>design only servers data models</strong>. Which leaves the freedom to system evolution in three dimensions: service side, client side and resource linkages(resource descriptions). In concept, RESTful is a series of constrains towards an open architecture for next 10 years. Therefore the key points are:</p><ul><li><strong>Stateless</strong>: Server side openness ☞ A dimension for Server side to evolute within the distributed system.</li><li><strong>Hyper-media driven</strong>: Business logic openness ☞ The dimension of freedom to support business evolution. Clients start from limited entry points and the requests are driven by hyperlinks in between.</li><li><strong>Uniform Interface</strong>: Client side openness ☞ A dimension for Client side to evolute and separate implementation details.</li></ul><p>HTTP is the only implementation base so far. In common practices, the verbs and constrains on verbs are mixed from HTTP or RESTful. In other words, in context of concrete implementations, some conventions are borrowed from HTTP constrains. </p><p>With HTTP and the using of HTTP Methods, RESTful also offers a kind of transparency to the network. <strong>Cache</strong> support is a widely mentioned feature comparing to traditional SOAP. With SOAP, the intermediate nodes can hardly know whether the operation is cache friendly unless it decode the message and find the Action Code within XML body. The existing HTTP headers as “modified-after-*” is not reusable with SOAP. But RESTful architecture can reuse existing infrastructures of Web Services and Network. It is friendly to existing Load Balance, CDN/Cache, and, Health-check facilities.</p><p>From a practice point of view, Infosys published a handbook describing three wheels of RESTful: the <em>Resources(URI)[^URI], Verbs(Methods) and Representation (Format)</em>. Before starting practicing, my recommendation is still to think more on what is resource and how the resources are represented in such a semi-transparent and open architecture sytle. </p><p>$\mathsf{\color{olive}{✐\ RESTful\ Maturity\ Model}}$: 4 Levels of RESTful Maturity definition to show the way to improve and where we are, by <a href="https://www.crummy.com/writing/speaking/2008-QCon/act3.html">Leonard Richardson</a>, 2008. </p><p><a href="https://imgur.com/3f6qnOE">![RESTful Maturity Model][https://i.imgur.com/3f6qnOEm.png]</a> </p><p>It is still debating whether the first three levels are within RESTful scope. Because the maturity model might mislead people to understand the objectives of RESTful to build an eco of HATEOAS. At least, a common understanding is the maturity model provides a way to evaluate on a growth view towards semantic network.</p><p>It is said that a large part of current online so-called RESTful services are quick works moved to HTTP verb driven, not hyper-media driven. And they are designed against operations, not resources.</p><h4 id="Level-0-Just-one-URI-as-XML-RPC"><a href="#Level-0-Just-one-URI-as-XML-RPC" class="headerlink" title="Level 0: Just one URI, as XML-RPC"></a>Level 0: Just one URI, as XML-RPC</h4><p>The HTTP headers have no relation with transaction data. It is just a sharing point. All business and model logic is encoded in payload with a tight coupling between clients and servers. The client must have internal knowledge on how server works.</p><h4 id="Level-1-Multiple-URI-but-one-method"><a href="#Level-1-Multiple-URI-but-one-method" class="headerlink" title="Level 1: Multiple URI but one method"></a>Level 1: Multiple URI but one method</h4><p>The RESTful degrades from Application Protocol to a Transportation Layer. As in SOAP or XML-RPC, an action code is in payload like “Do.Action” and “Operation=**“.</p><h4 id="Level-2-Multiple-URI-Multiple-method"><a href="#Level-2-Multiple-URI-Multiple-method" class="headerlink" title="Level 2: Multiple URI, Multiple method"></a>Level 2: Multiple URI, Multiple method</h4><p>Methods and Status Code in Headers are representing transaction logic.</p><p><em><em>Notes:</em></em></p><blockquote><p>CRUD: Post, Get, Put/PATCH, Delete<br>PUT: Update the whole object, while, PATCH: Update the properties of object.<br>HEAD: Fetch meta data.<br>OPTIONS: Fetch which properties can be altered</p></blockquote><h4 id="Level-3-Hypermedia-as-Application-Engine-–-HATEOAS"><a href="#Level-3-Hypermedia-as-Application-Engine-–-HATEOAS" class="headerlink" title="Level 3: Hypermedia as Application Engine – HATEOAS"></a>Level 3: Hypermedia as Application Engine – HATEOAS</h4><p>Leave the server side a freedom of service evolution. The application just enters from the entry point and will triger <strong>State Transfer</strong> on server objects via a hyperlinks.</p><p>GET: can use filter, paging, not idempotent, POST: seems better and it return links to results.</p><h4 id="Brief-History"><a href="#Brief-History" class="headerlink" title="Brief History"></a>Brief History</h4><p>When RESTful was published 2000, it was ahead of time. With more and more services were delivered in the name of RESTful, the situation was not getting better towards <strong>self-describable network</strong>. </p><p>When the first internet bubble was over, more studies were spent on this topic. The popular Rails makes <strong>CRUD</strong> a widely accepted concept in a narrowed context. Together with ROR is the dominancy trend of various application clients than browser. Mobile traffics exceeded desktop from 2016 and <a href="https://www.businessinsider.com.au/mobile-web-vs-app-usage-statistics-2014-4" title="mobile web vs app">Apps dominant mobile internet</a> More people turn to review this topic (from 2014) and publish articles and posts towards core concept of RESTful.<br><img src="http://oei21r8n1.bkt.clouddn.com/CRUD_20170527_7.png?imageView2/2/w/240" alt="CRUD Image"><br>In short, CRUD is a selected implementation offered by most of modern Apps and Frameworks. It can be roughly regarded as a craft way between level-2 and HATEOAS. While RESTful is on a higher abstract layer to define the architecture style. </p><h3 id="1-2-Applications"><a href="#1-2-Applications" class="headerlink" title="1.2 Applications"></a>1.2 Applications</h3><p>Two kinds: Browser and Other Application. The Clients details are protected from coupling up with distributed systems. However, it can be checked through the User-Agent header.</p><h3 id="1-3-Verbs-in-HTTP"><a href="#1-3-Verbs-in-HTTP" class="headerlink" title="1.3 Verbs in HTTP"></a>1.3 Verbs in HTTP</h3><h4 id="1-3-1-Safety-and-Idempotence"><a href="#1-3-1-Safety-and-Idempotence" class="headerlink" title="1.3.1 Safety and Idempotence"></a>1.3.1 Safety and Idempotence</h4><p>$\mathsf{\color{olive}{✐\ Safety}}$: The operation won’t change resource state on server side. Therefore if a safe operation is performed once or multiple times, the server state does not change as client never make the operation at all. </p><p><strong>Tips:</strong> Client does not know whether the server really does not change anything. Here safety is on <strong>service</strong> layer of perspective. The client does not couple up with whether server keeps audit, logs or runs an iterator as internal implementation. From a service layer view, if the resource remains, the uniformed interface with curren method is safe. So does Idempotence.</p><p><em><em>Notes:</em></em></p><blockquote><p><strong>Safety vs Security</strong>: In Chinese language, the two concepts are not distinguished by default. The two terms defined different scope in general English context. Safety refers to the infrastructural problems as climate disaster, earthquake, or, severes threats without indistinctive targets. Security is a bit narrow concept on individual level protection from explosing, targeted attacks.</p></blockquote><p>Examples: GET and HEAD are safe methods. POST is not safe.</p><p>$\mathsf{\color{olive}{✐ Idempotence}}$: The operation on resource(s) by making one request is the same as making a series of <em>identical</em> requests. This concept is from Maths. When an operation has same effect whether it is applied once or more than once. For example,$4\times0\times0 == 4\times0$. </p><p>Examples: GET, PUT and DELETE are idempotent. POST is not idempotent, neither.</p><p>HTTP v1.1 defines idempotence as:</p><blockquote><p>Methods can also have the property of “idempotence” in that (aside from error or expiration issues) the side-effects of N &gt; 0 identical requests is the same as for a single request.</p></blockquote><p>In distributed systems, idempotence is a key feature to decouple systems  to eliminate strong constrains. For example, withdraw money from a deposit</p><p>Safety and idempotency allow clients to make reliable request over unreliable network environment. If the operation is safe, it can be cached and mutiplied without worry about side effects. If it is idempotent, the request can be replayed in unreliable environment.</p><p>$\color{brown}{✓\ Misusing\ GET\ for\ Unsafe\ Operations}$<br>There is a common checkpoints for testing team to pay attention if safe metod as “GET” is misused to expose unsafe interfaces. </p><h4 id="1-3-2-Summary-of-HTTP-Methods"><a href="#1-3-2-Summary-of-HTTP-Methods" class="headerlink" title="1.3.2 Summary of HTTP Methods"></a>1.3.2 Summary of HTTP Methods</h4><table><thead><tr><th style="text-align:left">Method</th><th style="text-align:center">Safe</th><th style="text-align:center">Idempotent</th></tr></thead><tbody><tr><td style="text-align:left">POST</td><td style="text-align:center"><span style="color: red">no</span></td><td style="text-align:center"><span style="color: red">no</span></td></tr><tr><td style="text-align:left">GET</td><td style="text-align:center"><span style="color: green">yes</span></td><td style="text-align:center"><span style="color: green">yes</span></td></tr><tr><td style="text-align:left">HEAD</td><td style="text-align:center"><span style="color: green">yes</span></td><td style="text-align:center"><span style="color: green">yes </span></td></tr><tr><td style="text-align:left">PUT</td><td style="text-align:center"><span style="color: red">no</span></td><td style="text-align:center"><span style="color: green">yes </span></td></tr><tr><td style="text-align:left">PATCH</td><td style="text-align:center"><span style="color: red">no</span></td><td style="text-align:center"><span style="color: red">no</span></td></tr><tr><td style="text-align:left">DELETE</td><td style="text-align:center"><span style="color: red">no</span></td><td style="text-align:center"><span style="color: green">yes </span></td></tr><tr><td style="text-align:left">LINK</td><td style="text-align:center"><span style="color: red">no</span></td><td style="text-align:center"><span style="color: green">yes </span></td></tr><tr><td style="text-align:left">UNLINK</td><td style="text-align:center"><span style="color: red">no</span></td><td style="text-align:center"><span style="color: green">yes </span></td></tr></tbody></table><p><em><em>Notes:</em></em></p><blockquote><p><strong>PATCH</strong>: Unlike PUT, PATCH is not idempotent, both are not safe. Which is to say, PATCH is not required to be idempotent as I updates selected properties. Client shall not assume PATCH as idempotent operation. However, in purticular context, PATCH can be idempotent with headers “If-Match” or “If-Unmodified-Since”. </p></blockquote><blockquote><p>Another point, PATCH is not natively defined by HTTP specification. Which is introduced by RFC 5789, 2010 as an extension for Web APIs.</p></blockquote><blockquote><p><strong>GET</strong>: Safe and Idempotent. It is a hint to test cache via proxy or packet analyzer.</p></blockquote><blockquote><p><strong>POST</strong>: Two cases for POST method: Post-to-append (appending POST) and Post-to-overloaded (overloading POST). Post-to-append is the HTTP request to create a new resource beneath another resource. </p></blockquote><blockquote><p><strong>POST_and_PUT</strong>: POST regards the URI as resource “acceptor”, not the resource itself to create. <code>POST https://api.forum.com/articles</code> is to create an article “for” articles resource, or, owned by articles. In the return result links to the new resource shall be indicated. The 2nd POST request will create another URI for articles. Therefore POST is not safe, non-idempotent. </p><p>PUT is idempotent. <code>PUT https://api.forum.com/articles/101</code> is to update or create the resource “in” 101 URI. Multiple POST actions make no difference here. Hence PUT is idempotent method by definition. </p></blockquote><blockquote><p><strong>HEAD</strong>: Similar to GET but only has HTTP headers.</p></blockquote><blockquote><p><strong>OPTIONS</strong>: It is an HTTP native exploring verb. The return result holds a header of <HTTP Allow> which defines all methods current resource supports.</p></blockquote><blockquote><p><strong>LINK/UNLINK</strong>: It is not recommended to adapt LINK/UNLINK so far since it is not popular. The LINK/UNLINK are proposed in an IETF draft.</p></blockquote><h3 id="1-4-HTTP-Status-Code"><a href="#1-4-HTTP-Status-Code" class="headerlink" title="1.4 HTTP Status Code"></a>1.4 HTTP Status Code</h3><table><thead><tr><th style="text-align:left">Range</th><th style="text-align:center">Transition Information</th><th style="text-align:center">Notes</th></tr></thead><tbody><tr><td style="text-align:left">1XX</td><td style="text-align:center"><span style="color: blue">Information</span></td><td style="text-align:center"><span style="color: blue">100 - Continue</span></td></tr><tr><td style="text-align:left">2XX</td><td style="text-align:center"><span style="color: green">OK</span></td><td style="text-align:center"><span style="color: green">201 - Created <br> 204 - No Content</span></td></tr><tr><td style="text-align:left">3XX</td><td style="text-align:center"><span style="color: brown">Redirection</span></td><td style="text-align:center"><span style="color: brown">301 - Redirect Permanent <br>302 - Redirect Temporary </span></td></tr><tr><td style="text-align:left">4XX</td><td style="text-align:center"><span style="color: red">Client Error</span></td><td style="text-align:center"><span style="color: red">400 - Bad Request (Malformated) <br> 401 - Unauthorized <br> 403 - Forbidden <br> 404 - Not Found <br> 405 - Now Allowed (wrong method) <br> 409 - Resource Conflict</span></td></tr><tr><td style="text-align:left">5XX</td><td style="text-align:center"><span style="color: red">Server Error</span></td><td style="text-align:center"><span style="color: red">501 - Not Implemented <br> 505 - HTTP Version Not Supported</span></td></tr></tbody></table><p>It is widely seen in practices the return status code is only checked whether it is 2XX as in many front end applications. On syntax level, this is effective. However, it is recommended to apply semantic checks as well. For example, it the request is to <em>C</em>reate an entity, then the status code in the response header is expected to be “201”. On the other hand, when the request is to <em>D</em>elete an entity, the status code is expected to be “204”.</p><p>From the architecture view, if a Front-End App triggers a state change via request to a service or micro-service, and the payload is transparently carried over to downstream micro-services. When the downstream service reports an payload error as 4XX (client side error), what would be returned to the Front-End App? It will depend on the information disclosure from overall strategy. For many of the applications, the Front-End runs in Browser or Mobile are not permitted to disclose more information for security sake. Therefore, it is possible to see 5XX errors on Front-End instead.</p><p><em><em>Notes:</em></em><br>Here is a <a href="https://i.stack.imgur.com/whhD1.png">complete decision diagram</a> on HTTP status code.<br>For a quick reference on HTTP status code, readers are recommended to visit <a href="https://httpstatuses.com/">httpstatuses.com</a></p><h2 id="2-Testing-RESTful-APIs"><a href="#2-Testing-RESTful-APIs" class="headerlink" title="2 Testing RESTful APIs"></a>2 Testing RESTful APIs</h2><p>In current section, the check points list is shared. It will be maintained lively. The list shall be able to apply in architecture review and testing works directly. I would try to add more concrete examples in following days.</p><p><strong>✓ HTTPs protocol always</strong></p><p>As common practice, CircleCI, travis-ci and Github are on HTTPs. However there are still couple of issues to pay special attention on security (refer to previous tips section in this post on safety vs security).</p><ul><li>Certificate verification between peers, which can reuse HTTPs infrastructure;</li><li>API keys to offer an RBAC or other access control;</li><li>Allow one client to work with multiple API keys;</li><li>Adapt <strong>API-key + Secret-Key</strong>, sign key value pairs before URL encoding;</li></ul><p>It is recommended to take a further step from API-key authentication to API-Key + Secret-Key authentication with a convention of <strong>Request Signature</strong>. It is hard to say which signature procedure is “right”. There are several good practices to refer as Amazon AWS API parameter signature (v2.0, v1.0 is insecure), Baidu API and other famous providers. Here is a sample from developer.baidu.com. The URL parameters are signed with timestamp in predefined format and key value sorted in ascending order with session_secret appended. A kind reminder is to add timestamp as mentioned common practice to ignore expired requests. This protects services from Replay and Man-In-The-Middle attacks.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /rest/2.0/passport/users/getInfo?session_key=9XNNXe66zOlSassjSKD5gry9BiN61IUEi8IpJmjBwvU07RXP0J3c4GnhZR3GKhMHa1A%3D&amp;timestamp=2011-06-21+17%3A18%3A09&amp;format=json&amp;uid=67411167&amp;sign=d24dd357a95a2579c410b3a92495f009 HTTP/1.1</span><br><span class="line">Host: openapi.baidu.com</span><br><span class="line">User-Agent: Client of Baidu Open Platform</span><br><span class="line">Accept: */*</span><br><span class="line">Accept-Encoding: gzip,deflate</span><br><span class="line">Accept-Charset: utf-8</span><br><span class="line">Connection: close</span><br></pre></td></tr></table></figure><p>Here is code sample from AWS on how to sign requests to AWS API.<br><a href="http://docs.aws.amazon.com/general/latest/gr/sigv4-signed-request-examples.html?shortFooter=true">http://docs.aws.amazon.com/general/latest/gr/sigv4-signed-request-examples.html?shortFooter=true</a></p><ul><li>CircleCI API runs on HTTPs, but not with signed request.</li><li>Travis-CI takes token from HTTP auth header also.</li></ul><p><strong>✓ Prefer to locate API to subdomain as <code>api.dome.com</code> instead of <code>domain.com/api</code></strong></p><p>This piece of tips makes APIs friendly to the network including Routers, Firewalls and Domain security infrastructures.</p><ul><li>CircleCI API service is not on subdomain, <code>https://circleci.com/api/v1.1/</code></li><li>Travis-CI runs service on <code>https://api.travis-ci.com/</code></li></ul><p><strong>✓ Combine version to URI, e.g. <code>api.domain.com/v1</code></strong></p><ul><li>CircleCI URI combines up version information.</li><li>Travis-CI accepts API version from HTTP Header.</li></ul><p><strong>✓ Use nouns but not verbs.</strong></p><ul><li>Plura nouns in most time</li><li>Nouns in plura reflect table names in DB</li></ul><p>Take below example from CircleCI API doc, cancel here is regarded as a resource like command queue. Travis-CI has similar interface <code>/job/&#123;job.id&#125;/cancel</code>. Here job.cancel will accept a resouce of command with POST.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">POST: /project/:vcs-type/:username/:project/:build_num/cancel</span><br><span class="line">Cancels the build, returns a summary of the build.</span><br></pre></td></tr></table></figure><p><strong>✓ Verbs (Methods) correctly utilized</strong></p><p>An example from Travis-CI API doc about ‘PATCH’ method to update properties:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PATCH</span><br><span class="line">/repo/&#123;repository.id&#125;/setting/&#123;setting.name&#125;</span><br></pre></td></tr></table></figure><ul><li>CRUD: Post, Get, Put/Patch, Delete</li><li>Head/Options</li><li>Get is idempotent (with all parameters)</li></ul><p><strong>✓ Filtering, Sorting, Selecting, Limit/Pagination Supports</strong></p><p>An example of RUI with pagination <code>api.domain.com/v1/zoos?id=2&amp;limit=10</code></p><ul><li>Travis-CI offers <a href="https://developer.travis-ci.com/pagination">pagination supports</a></li></ul><p><strong>✓ Status Code</strong></p><p>As mentioned in section 1.4, status codes are expected to be compliant to HTTP convention.</p><p><strong>✓ Error Handling</strong></p><p>RESTful service returns verbose error information in Payloads, e.g. <code>&#123;error: &quot;XXX&quot;&#125;</code></p><ul><li><p>Travis-CI error message example:</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;@type&quot;</span>:  <span class="string">&quot;home&quot;</span>,</span><br><span class="line"> <span class="attr">&quot;@href&quot;</span>:  <span class="string">&quot;/&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;errors&quot;</span>: &#123;</span><br><span class="line">   <span class="attr">&quot;login_required&quot;</span>: &#123;</span><br><span class="line">      <span class="attr">&quot;status&quot;</span>:                <span class="number">403</span>,</span><br><span class="line">      <span class="attr">&quot;default_message&quot;</span>:       <span class="string">&quot;login required&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;additional_attributes&quot;</span>: [ ]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;method_not_allowed&quot;</span>: &#123;</span><br><span class="line">      <span class="attr">&quot;status&quot;</span>:                <span class="number">405</span>,</span><br><span class="line">      <span class="attr">&quot;default_message&quot;</span>:       <span class="string">&quot;method not allowed&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;additional_attributes&quot;</span>: [ ]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;not_found&quot;</span>:&#123;</span><br><span class="line">      <span class="attr">&quot;status&quot;</span>: <span class="number">404</span>,</span><br><span class="line">      <span class="attr">&quot;default_message&quot;</span>: <span class="string">&quot;resource not found (or insufficient access)&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;additional_attributes&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;resource_type&quot;</span></span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p><strong>✓ Return Result compliancy</strong></p><ul><li>A set or an obj.</li><li>Sub resources for relations: </li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /cars/711/drivers/ Returns a list of drivers for car 711</span><br><span class="line">GET /cars/711/drivers/4 Returns driver #4 for car 711</span><br></pre></td></tr></table></figure><p><strong>✓ Hypermedia context</strong></p><p>Provides Hyperlink driven APIs as manual exploring with the services.</p><p><strong>✓ Allowing Overriding Methods</strong></p><p>Use <code>X-HTTP-Method-Override</code> in cases some proxies only supports POST and GET.</p><h2 id="3-Test-the-RESTful-Service"><a href="#3-Test-the-RESTful-Service" class="headerlink" title="3 Test the RESTful Service"></a>3 Test the RESTful Service</h2><p>(TODO)</p><h2 id="4-DevOps-on-RESTful-Service"><a href="#4-DevOps-on-RESTful-Service" class="headerlink" title="4 DevOps on RESTful Service"></a>4 DevOps on RESTful Service</h2><h3 id="Dashboard-on-Delivery-Pipeline"><a href="#Dashboard-on-Delivery-Pipeline" class="headerlink" title="Dashboard on Delivery Pipeline"></a>Dashboard on Delivery Pipeline</h3><h3 id="Dashboard-on-E2E-RESTful-Status"><a href="#Dashboard-on-E2E-RESTful-Status" class="headerlink" title="Dashboard on E2E RESTful Status"></a>Dashboard on E2E RESTful Status</h3><p>(TODO)</p><h2 id="5-References"><a href="#5-References" class="headerlink" title="5 References"></a>5 References</h2><p><a href="https://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm" title="Architectural Styles and the Design of Network-based Software Architectures">Roy Thomas Fielding Phd Dessertation</a></p><p><a href="https://en.wikipedia.org/wiki/Representational_state_transfer" title="RESTful Wiki">Wikipedia RESTful Term</a></p><p><a href="https://www.crummy.com/">Leonard Richardson Personal Site</a><br><a href="https://blog.mwaysolutions.com/2014/06/05/10-best-practices-for-better-restful-api/">10 Best Practices for better RESTful</a></p><p><a href="http://restcookbook.com/">REST Cookbook</a><br><a href="https://www.businessinsider.com.au/mobile-web-vs-app-usage-statistics-2014-4" title="mobile web vs app">mobile web vs app</a></p><p><a href="https://raw.githubusercontent.com/for-GET/http-decision-diagram/master/httpdd.png">HTTP Status Code Decision Diagram in High Resolution</a></p><p><a href="https://circleci.com/docs/api/v1-reference/">Circle CI API v1.1</a></p><p><a href="https://docs.travis-ci.com/api">Travis CI API</a></p><p><a href="https://wiki.jenkins-ci.org/display/JENKINS/Remote+access+API">Jenkins Remote API</a></p><p><a href="http://broadcast.oreilly.com/2009/12/principles-for-standardized-rest-authentication.html">Principles for Standardized RESTful Authentication</a></p><p><a href="http://docs.aws.amazon.com/general/latest/gr/signing_aws_api_requests.html">Signing AWS Request</a></p><h2 id="6-Change-Logs"><a href="#6-Change-Logs" class="headerlink" title="6 Change Logs"></a>6 Change Logs</h2><p>Jun 02, 2019: Fix image links and update HTTP status code section.<br>May 29, 2017: Add security check point examples.<br>May 27, 2017: Minor change, updated pictures.<br>May 23, 2017: Updated HTTP methods and Status Code overview.<br>May 20, 2017: Initial the draft.</p><h2 id="7-Terms-and-Notes"><a href="#7-Terms-and-Notes" class="headerlink" title="7 Terms and Notes"></a>7 Terms and Notes</h2><p>[^URI]: URI - The Uniform Resource Identifier has two forms: URN and URL. URN maps resources by unique names and URL locates resources with unique locations. </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This article is inspired by another post described the disapproving on current common misunderstanding among concepts of RESTful, CRUD, Safety, Security and Idempotency.&lt;br&gt;&lt;a href=&quot;https://imgur.com/tS7bZ9i&quot;&gt;![RESTful Img][https://i.imgur.com/tS7bZ9im.png]&lt;/a&gt;&lt;br&gt;This post targets to rephase RESTful concept and describes common check points against RESTful API architecture test during Software Design Review.As practical samples, Jenkins API and CircleCI/TravisCI API will be analyzed, tested and evaluated.&lt;br&gt;
    
    </summary>
    
      <category term="Automation Test" scheme="http://maxwu.me/categories/Automation-Test/"/>
    
      <category term="RESTful" scheme="http://maxwu.me/categories/Automation-Test/RESTful/"/>
    
    
      <category term="RESTful" scheme="http://maxwu.me/tags/RESTful/"/>
    
      <category term="Architecture" scheme="http://maxwu.me/tags/Architecture/"/>
    
  </entry>
  
  <entry>
    <title>BFS solution of power sum challenge</title>
    <link href="http://maxwu.me/2017/05/16/BFS-solution-of-power-sum-challenge/"/>
    <id>http://maxwu.me/2017/05/16/BFS-solution-of-power-sum-challenge/</id>
    <published>2017-05-16T10:18:19.000Z</published>
    <updated>2021-10-24T22:03:14.504Z</updated>
    
    <content type="html"><![CDATA[<p>This post described a python solution on coding challenge “the power sum” (med) and common points on BFS algorithm. <strong>The_Power_Sum</strong> asks how many solutions on equation $n_1^x + n_2^x + .. n_i^x = n$ when $n_1, n_2, n_i \in [1, n]$<br><span id="more"></span></p><h2 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h2><p>Given positive numbers $n,x$ and find how many solutions can satisfy $n_1^x + n_2^x + .. n_i^x = n$ when $n_1, n_2, n_i \in [1, n]$. Since every number is unique and only shows up once from $[1,n]$, with the symmetry of $+$ operation, the answer is how many combinations from set $[1,n]$, not permutation. On a general perspective of view, the solution space is within $\sum_{i=1}^n C(^n_k)$, which is $2^n$.</p><p>For example, if n is 10 and x is 2 then there answer is 1 since there is only one solution of $1^2 + 3^2 = 10$. But 100, 2 would get 3 as answer because $100 = 10^2 = 6^2 + 8^2 = 1^2 + 3^2 + 4^2 + 5^2 + 7^2$.</p><h2 id="Rephrase-the-Problem-to-Mathimatical-Language"><a href="#Rephrase-the-Problem-to-Mathimatical-Language" class="headerlink" title="Rephrase the Problem to Mathimatical Language"></a>Rephrase the Problem to Mathimatical Language</h2><h3 id="Terminology"><a href="#Terminology" class="headerlink" title="Terminology"></a>Terminology</h3><p><strong>BFS</strong>: Breadth First Search. Classic BFS defines problem as a search in space described by set V, E where each V as vertex has a set of E ($V_i \to V_j$ where $V_i, V_j \in V$). </p><p>The worst performance is $O(|V| + |E|)$ because it travels from all candidate vertexes and loops all possible $E_i$. Therefore, to cache all the candidate partial results, the worst space complexity is $O(|V|)$. Here $E$ only describes the state transition and a $O(|V|)$ structure queues the concerned information on paths.</p><p>The classic BFS procedure is straight, simple and useful. We can find the transformed BFS in DB join query, distributed query on indexes or caches, Fast Hashing, GeoApps as Navigator and Shopping Guide Apps. Keys within fundamental algorithms are how to apply the abstract model to real worlds $\lambda \to \pi$. The most natrual principal of computer system design is to mimic a structure which represents the nouns of concepts from real world. Which requests a map from machine space to human view space.</p><h3 id="Problem-Space"><a href="#Problem-Space" class="headerlink" title="Problem Space"></a>Problem Space</h3><p>To apply the thoughts of DFS and BFS algorithm we shall rephase the problem to a typical search in given logical sapce. Moreover, if we generally define a vector to present the tracks of current search, a set of vector could be regarded as the set of partial search results.</p><h3 id="Intermediate-Result-Set"><a href="#Intermediate-Result-Set" class="headerlink" title="Intermediate Result Set"></a>Intermediate Result Set</h3><p>BFS, as how the term is coined, will cache the intermediate results and move forward on all of them during each step. So it is fair to all possible branches. That’s why it can find the fastest path(s).</p><p>Here search sapce it numbers of [1, n]. Since each number can only show up once or not, we have n vertexes on a linear space. We can assign 0, 1 to the vertex to mark it picked up or not picked-up in current search branch. The string of ‘0’ and ‘1’ can represent a path of current search and the strings in list can play the data structure as the intermediate vectors of partial search results.</p><h3 id="Algorithm-Application-Key-Points"><a href="#Algorithm-Application-Key-Points" class="headerlink" title="Algorithm Application Key Points:"></a>Algorithm Application Key Points:</h3><p>My <a href="http://maxwu.me/2017/05/02/Recursive-Depth-First-Search-with-a-tracking-Set/">previous post</a> is about a common recursive design of DFS. It emphasized two key steps to form a recursive solution. </p><ul><li>✎ Termination condition: For DFS, it is the test whether to record the result as a success and whether to continue the search. Back to current problem, I stop the branch because it is not meaningful to add any positive number since the summary is already satisfied or even exceeded.<ul><li>Whether to record the success path when termination state found</li><li>Whether to continue search: if there is a cycle of arcs from one termination state to another termination state and the path is meaningful, we shall continue but be reminded of cycles in search. </li></ul></li><li>✎ How to reduce: “Reduce” is a term to apply the sub-problem (current scope of search) of DFS to join the other branch of search.</li></ul><p>For a BFS algorithm, we evaluate all branches on the same depth level in search. Sometimes the depth is a term of cost. Here for current problem, we can assign the number of positive numbers visited as the depth of search. </p><p>On each step, BFS check the partial search result set and work on all partial paths. Usually we loop all of the candidates and move forward one step if the candidate can generate further paths to search.</p><h3 id="Smart-Search"><a href="#Smart-Search" class="headerlink" title="Smart Search"></a>Smart Search</h3><p>A loop on all candidates is mentioned in above section. However, it could be generalized to a weight based candidate set. So a ranking based on partial results can be assessed. Based on what we know for each step, the weight will be adjusted. A smart search can work from high ranked candidate branch to the low ranked ones. Which is also the key to $A^*$ algorithm although heuristic algorithms are not within the scope of this post. </p><p>In current solution to “The Sum of Power” coding challenge, we just force the exceeded partial search paths do not take any more number. It is to cut off not useful branches in the search space. </p><p>To shrink the search scope for this particular problem, uplimit is calculated because for $n_i &gt; \sqrt[X]N where i \in [1, n]$ the $n_i$ is safe to bypass. Each element has two branches on search paths, ‘1’: selected, ‘0’: bypassed, so search space is within $2^{lmt}$.</p><h2 id="Solution-and-code"><a href="#Solution-and-code" class="headerlink" title="Solution and code"></a>Solution and code</h2><p>With above understanding, turning design into codes is a straight and clear action. The BFS codes have 11 lines in Python to search given space.</p><p>A dict is introduced to queue the intermediate results as {<strong>search path in 0|1 string : partial sum</strong> }.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bfs</span>(<span class="params">lmt, tgt, pwr</span>):</span></span><br><span class="line">    rec = &#123;<span class="string">&#x27;&#x27;</span>: <span class="number">0</span>&#125;  <span class="comment"># candidates in str: int format</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, lmt+<span class="number">1</span>):</span><br><span class="line">        tmp_rec = <span class="built_in">dict</span>() <span class="comment"># The candidate E for futher steps</span></span><br><span class="line">        <span class="keyword">for</span> k,v <span class="keyword">in</span> rec.iteritems():</span><br><span class="line">            <span class="keyword">if</span> v &lt; tgt:</span><br><span class="line">                tmp_rec[k+<span class="string">&#x27;1&#x27;</span>] = v + i**pwr <span class="comment"># Take a step forward on this path with &#x27;1&#x27; branch</span></span><br><span class="line">                tmp_rec[k+<span class="string">&#x27;0&#x27;</span>] = v <span class="comment"># Take a step on &#x27;0&#x27; branch</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                tmp_rec[k+<span class="string">&#x27;0&#x27;</span>] = v <span class="comment"># Can only take &#x27;0&#x27; branch</span></span><br><span class="line">        rec = tmp_rec</span><br><span class="line">    <span class="keyword">return</span> [k <span class="keyword">for</span> k, v <span class="keyword">in</span> rec.iteritems() <span class="keyword">if</span> v == tgt]</span><br><span class="line"></span><br><span class="line"><span class="comment"># __main__</span></span><br><span class="line">x, n = [<span class="built_in">int</span>(raw_input().strip())<span class="keyword">for</span> _ <span class="keyword">in</span> xrange(<span class="number">2</span>)]</span><br><span class="line">lmt = <span class="built_in">int</span>(<span class="built_in">round</span>(x ** (<span class="number">1.0</span>/n))) + <span class="number">1</span></span><br><span class="line">ss = bfs(lmt, x, n)</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">len</span>(ss)</span><br></pre></td></tr></table></figure><p>We could not alter an iterator within the iteration loop with Python (or other langauge like Java). So a tmp_rec is introduced to queue those partial paths which are meaningful to take further efforts to catch up and search deeper. </p><h1 id="Following-Up"><a href="#Following-Up" class="headerlink" title="Following Up"></a>Following Up</h1><p>This problem is a common BFS application occasion. As we have above implementation for BFS, a general way of coding can be applied to other BFS solution. </p><p>(TBC: Would get back and add other generalized BFS solving examples.)</p><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ul><li><p>The coding challenge link, <a href="https://www.hackerrank.com/challenges/the-power-sum">https://www.hackerrank.com/challenges/the-power-sum</a> </p></li><li><p>Previous Post, <a href="http://maxwu.me/2017/05/02/Recursive-Depth-First-Search-with-a-tracking-Set">http://maxwu.me/2017/05/02/Recursive-Depth-First-Search-with-a-tracking-Set</a></p></li></ul><h1 id="Change-Log"><a href="#Change-Log" class="headerlink" title="Change Log"></a>Change Log</h1><ul><li>May 18, 2017: Change to MathJax format to rewrite equations clearly.</li><li>May 16, 2017: Finish the initial draft.</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This post described a python solution on coding challenge “the power sum” (med) and common points on BFS algorithm. &lt;strong&gt;The_Power_Sum&lt;/strong&gt; asks how many solutions on equation $n_1^x + n_2^x + .. n_i^x = n$ when $n_1, n_2, n_i \in [1, n]$&lt;br&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://maxwu.me/categories/Programming/"/>
    
      <category term="Python" scheme="http://maxwu.me/categories/Programming/Python/"/>
    
    
      <category term="Python" scheme="http://maxwu.me/tags/Python/"/>
    
      <category term="Algorithm" scheme="http://maxwu.me/tags/Algorithm/"/>
    
      <category term="BFS" scheme="http://maxwu.me/tags/BFS/"/>
    
  </entry>
  
</feed>
