<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>+U Maxout!</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.maxwu.me/"/>
  <updated>2021-10-19T11:00:00.000Z</updated>
  <id>https://www.maxwu.me/</id>
  
  <author>
    <name>Max Wu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Build k8s apps running both in and out of Cluster</title>
    <link href="https://www.maxwu.me/2021/10/20/Build-k8s-apps-running-both-in-and-out-of-Cluster/"/>
    <id>https://www.maxwu.me/2021/10/20/Build-k8s-apps-running-both-in-and-out-of-Cluster/</id>
    <published>2021-10-19T11:00:00.000Z</published>
    <updated>2021-10-19T11:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.imgur.com/FFtL6Fhm.png" title="Docker Helm Kubernetes" /></p><p>When building k8s apps, e.g. a reverse proxy to route APIs in given business domain, helm chart is a convenient choice to build and ship the apps. Sometimes if it's a prototype, your teammates or yourself would think of running it in local for quick verification in local cluster or a better debug way. This post described the tips to build an app running both in and out of the cluster</p><span id="more"></span><h2 id="problem-description">Problem Description</h2><p>In short, the app is expected to run in local for debug and quick demo using but it shall also be delivered in helm chart and deployed in realistic environment for a further step prototype with downstream services.</p><h2 id="clientset-configuration">ClientSet Configuration</h2><p>In my practice, the kube client is usually a ClientSet with CRD schemed and for convenience we could keep the k8s core scheme client together with CRD clientset as below. The kube client could be simply declared in the app sub package and injected from <code>main.go</code>.</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> KubeClientSet <span class="keyword">struct</span> &#123;</span><br><span class="line">  <span class="comment">// Your CRD schemed clientset</span></span><br><span class="line">Client    *cltv1.V1Client</span><br><span class="line">  <span class="comment">// K8s clientset</span></span><br><span class="line">K8sClient *kubernetes.Clientset</span><br><span class="line">  <span class="comment">// Host is extraced from K8sClient for service URL building</span></span><br><span class="line">Host      <span class="keyword">string</span></span><br><span class="line">InCluster <span class="keyword">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Then in the <code>NewKubeClient()</code> when the clientset is initialized, the host name is filled to adapt in and out of cluster cases. Where the flag <code>InCluster</code> could be resolved as <code>os.Getenv("KUBERNETES_SERVICE_HOST") != ""</code>. If an app is running in kubernetes cluster container and it's not intended to prevented to visit the cluster host API, the <code>KUBERNETES_SERVICE_HOST</code> shouldn't be empty.</p><p>Another reminder is k8s runtime pkg also defines <code>kubeconfig</code> CLI flag, so readers could use <code>flag.Lookup()</code> to check it first. <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">GetKubeConfig</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> kubeconfig <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> !InCluster() &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Running out of cluster</span></span><br><span class="line">homeDir, _ := os.UserHomeDir()</span><br><span class="line">defaultKc := homeDir + <span class="string">&quot;/.kube/config&quot;</span></span><br><span class="line"><span class="comment">// k8s-sig runtime also defines kubeconfig flag. It might be removed in later version.</span></span><br><span class="line">kcFlag := flag.Lookup(<span class="string">&quot;kubeconfig&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> kcFlag == <span class="literal">nil</span> &#123;</span><br><span class="line">flag.StringVar(&amp;kubeconfig, <span class="string">&quot;kubeconfig&quot;</span>, defaultKc, <span class="string">&quot;path to Kubernetes config file&quot;</span>)</span><br><span class="line">kcFlag = flag.Lookup(<span class="string">&quot;kubeconfig&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">flag.Parse()</span><br><span class="line">kubeconfig = kcFlag.Value.String()</span><br><span class="line"><span class="keyword">if</span> kubeconfig == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">kubeconfig = defaultKc</span><br><span class="line">&#125;</span><br><span class="line">log.Printf(<span class="string">&quot;Loading kubeconfig from %s&quot;</span>, kubeconfig)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">log.Printf(<span class="string">&quot;Running in cluster..&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> kubeconfig</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>At last, the <code>NewKubeClient()</code> shall check if it's running out of cluster, fill the <code>Host</code> field with the kube-proxy URL, e.g. <code>localhost:8888</code> if the kube-proxy for local test is <code>kubectl proxy --port=8888</code>. Otherwise, set the <code>Host</code> to its <code>kubeconfig.Host</code>.</p><h2 id="service-url-building">Service URL Building</h2><p>When a targeted service is located with namespace and service name, the URL could be built for in and out of cluster cases.</p><p>If it's running in cluster, the URL to a service is <code>&lt;svc_name&gt; + "." + &lt;svc_ns&gt; + ".svc." + CORE_DNS_HOST</code>. The coreDNS host usually is <code>cluster.local</code> but it's up to cluster configuration.</p><p>Otherwise, if it's running out of cluster and connecting to cluster API via kube-proxy, the URL is <code>Host + "/api/v1/namespaces/" + &lt;svc_ns&gt; + "/services/" + &lt;svc_name&gt; + "&lt;:port_name&gt;/proxy"</code>. <code>HOST</code> is the host value resolved in <code>NewKubeClient()</code> method.</p><p>The tricky point is the <code>&lt;:port_name&gt;</code>. If targeted port of the service is a named port, the port name is required.</p><h2 id="deployment-and-running">Deployment and Running</h2><p>Assume the RBAC is configured well, the k8s app is able to run out of cluster or be packaged up in a helm chart to be deployed in a cluster. To run it out of cluster for a quick demo, users need to launch kube-proxy first to expose the service from its running node.</p><h2 id="change-log">Change Log</h2><p>Oct, 2021: Initial post draft.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/FFtL6Fhm.png&quot; title=&quot;Docker Helm Kubernetes&quot; /&gt;&lt;/p&gt;
&lt;p&gt;When building k8s apps, e.g. a reverse proxy to route APIs in given business domain, helm chart is a convenient choice to build and ship the apps. Sometimes if it&#39;s a prototype, your teammates or yourself would think of running it in local for quick verification in local cluster or a better debug way. This post described the tips to build an app running both in and out of the cluster&lt;/p&gt;
    
    </summary>
    
      <category term="Programming" scheme="https://www.maxwu.me/categories/Programming/"/>
    
      <category term="Golang" scheme="https://www.maxwu.me/categories/Programming/Golang/"/>
    
    
      <category term="Kubernetes" scheme="https://www.maxwu.me/tags/Kubernetes/"/>
    
      <category term="Golang" scheme="https://www.maxwu.me/tags/Golang/"/>
    
      <category term="ClientSet" scheme="https://www.maxwu.me/tags/ClientSet/"/>
    
  </entry>
  
  <entry>
    <title>Golang empty []byte serialized to nil not []</title>
    <link href="https://www.maxwu.me/2021/10/02/Golang-empty-byte-serialized-to-nil-not/"/>
    <id>https://www.maxwu.me/2021/10/02/Golang-empty-byte-serialized-to-nil-not/</id>
    <published>2021-10-01T11:00:00.000Z</published>
    <updated>2021-10-01T11:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>Slices and arrays are differnet in golang serialization details. An uninitialized slice will be marshalled to JSON "null" value instead of "[]".</p><span id="more"></span><h2 id="uninitialized-slice">Uninitialized Slice</h2><p>Given a simple RESTful listing handler, the uninitialized slice could still be appended with query result iteration by overwriting the slice variable.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var s []string</span><br><span class="line">for _, item := range someResult &#123;</span><br><span class="line">  s = append(s, item)</span><br><span class="line">&#125;</span><br><span class="line">res, _ := json.Marshal(struct&#123; Items []string &#125;&#123;Items: s&#125;)</span><br><span class="line">fmt.Printf(&quot;res = %s\n&quot;, res)</span><br></pre></td></tr></table></figure><p>However, when the query result is empty, the uninitialized slice will be encoded to <code>null</code>. In this case, if <code>someResult</code> is empty, the output will be <code>res = &#123;"Items":null&#125;</code>. It's sometimes unfriendly to downstream APIs - usually the listing request expects an empty JSON array but not a null result.</p><h2 id="initialized-slice">Initialized Slice</h2><p>In the above case, the slice shall be initialized first. For an empty start value, it could be initialized to zero sized and the re-slice procedure will automatically extend it in go-runtime doubling algorithm.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var s []string = make([]string, 0) // or s:= []string&#123;&#125;</span><br><span class="line">for _, item := range someResult &#123;</span><br><span class="line">  s = append(s, item)</span><br><span class="line">&#125;</span><br><span class="line">res, _ := json.Marshal(struct&#123; Items []string &#125;&#123;Items: s&#125;)</span><br><span class="line">fmt.Printf(&quot;res = %s\n&quot;, res)</span><br></pre></td></tr></table></figure><p>If the query result is empty, it will still print <code>res = &#123;"Items":[]&#125;</code>. Same tips on <code>map</code>, an uninitialized reference type will be marshalled to "null" not an empty value.</p><h2 id="change-log">Change Log</h2><p>Oct, 2021: Initial post draft.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Slices and arrays are differnet in golang serialization details. An uninitialized slice will be marshalled to JSON &quot;null&quot; value instead of &quot;[]&quot;.&lt;/p&gt;
    
    </summary>
    
      <category term="Programming" scheme="https://www.maxwu.me/categories/Programming/"/>
    
      <category term="Golang" scheme="https://www.maxwu.me/categories/Programming/Golang/"/>
    
    
      <category term="Golang" scheme="https://www.maxwu.me/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>Build Declarative APIs</title>
    <link href="https://www.maxwu.me/2021/08/11/Build-Declarative-APIs/"/>
    <id>https://www.maxwu.me/2021/08/11/Build-Declarative-APIs/</id>
    <published>2021-08-10T12:00:00.000Z</published>
    <updated>2021-08-10T12:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.imgur.com/SB7st1gl.png" title="Declarative Interface" /></p><p>Declarative APIs or declarative models are popular in k8s cloud native apps. This post shares the experience and thoughts on learning and building a declarative interface prototype.</p><span id="more"></span><h2 id="declarative-model">Declarative Model</h2><p>A declarative software model, usually compared to imperative interface, includes a concept model of northbound scheme or DSL which describes a desired state of system and a southbound provider as a controller of async reconciliations.</p><h3 id="model-overview">Model Overview</h3><ul><li><strong>Northbound</strong>:<ul><li>A scheme or DSL to describe desired state of system</li><li>From users' view, it's the state being requested to declarative API, not the ways to do it</li><li>Usually the request is processed in an async way, e.g. ordering way</li></ul></li><li><strong>Southbound</strong><ul><li>One or more southbound providers in backend</li><li>The app could carry a default provider in most of cases, e.g. to call a traditional RESTful API in backend</li><li>The provider would reconcile the in scope object states towards desired states by:<ul><li>Calculate the state diff, usually in top to bottom or state tree model</li><li>The processing could be distributed and usually in async with workers</li><li>Once the calculated diff is empty, stop reconciliation</li><li>Generate requests to reconcile the targeted objects<ul><li>It's up the system dependencies but the experience is to reconcile one step at a time</li><li>If there are still more steps to go, complete current reconciliation step and requeue the request</li><li>Take care of low level requirements on the generated downstream requests<ul><li>Auth-n and auth-z with tenancies</li><li>Rate-limit with tenancies and cloud service provider</li><li>Charging or order management and traceabilities</li><li>Payload formats</li><li>Related east-west interactions, e.g. provider dependencies</li></ul></li></ul></li></ul></li></ul></li></ul><p>A typical example is the Terraform with providers.</p><h3 id="benifits-or-problems-to-resolve">Benifits or Problems To Resolve</h3><ul><li>Reduce Human Error</li></ul><p>Reports show around 1/5 outage incidents occur because of human error. In an imperative model, users need to consider each detail API request, version, phased validation and usually programmatically manage the intermediate states in sequence or async ways. From another point of view, the user end implements a work-flow implicitly. It increases the chances to introduce human errors due to the conflicts between humanity and complexity.</p><ul><li>Better and Earlier Validation</li></ul><p>(TBC)</p><ul><li>Hide the Technical Details</li></ul><p>With declarative interface, users don't deal with number of versions for all the APIs. There could still be version of scheme, which is an universal version or grouped versions in a relatively simpler way. The backend services could evolve without user end impacts.</p><h2 id="provider-design">Provider Design</h2><p>(TBC)</p><h2 id="open-questions">Open Questions</h2><ul><li>Benifits and examples of manifest model</li></ul><p>(TBC)</p><h2 id="change-log">Change Log</h2><p>Nov24, 2021: Continue drafting the model overview section. Mar15, 2021: Initial post draft.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/SB7st1gl.png&quot; title=&quot;Declarative Interface&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Declarative APIs or declarative models are popular in k8s cloud native apps. This post shares the experience and thoughts on learning and building a declarative interface prototype.&lt;/p&gt;
    
    </summary>
    
      <category term="Cloud" scheme="https://www.maxwu.me/categories/Cloud/"/>
    
      <category term="Declarative API" scheme="https://www.maxwu.me/categories/Cloud/Declarative-API/"/>
    
    
      <category term="Kubernetes" scheme="https://www.maxwu.me/tags/Kubernetes/"/>
    
      <category term="Declarative Model" scheme="https://www.maxwu.me/tags/Declarative-Model/"/>
    
  </entry>
  
  <entry>
    <title>Acquired Oracle Cloud Infrastructure 2020 Certified Architect Associate Cert</title>
    <link href="https://www.maxwu.me/2021/05/10/Acquired-Oracle-Cloud-Infrastructure-2020-Certified-Architect-Associate-Cert/"/>
    <id>https://www.maxwu.me/2021/05/10/Acquired-Oracle-Cloud-Infrastructure-2020-Certified-Architect-Associate-Cert/</id>
    <published>2021-05-09T12:00:00.000Z</published>
    <updated>2021-05-09T12:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.imgur.com/PomqC9ws.png" title="OCI Architect Associate Cert Link" /></p><p>OCI (Oracle Cloud Infrastructure) launched free learning and certifcate exam promotion in 2021. I took the exam on May 10, 2021 and acquired the score 89% at the firs attempt. A <a href="https://www.credly.com/badges/aa7fb3e1-0e2c-41f2-b4ad-a3c862bf6265">OCI Certificate Badge</a> will be available within couple of steps in a following email when you knocked the cert exam - usually within 2 working days. Here are some tips shared with readers.</p><span id="more"></span><ul><li><p>Due to pandemic, learners can choose to take the exam at home. I registered with Pearson and took the exam with pearson apps on my MacBook. A kind reminder to to run the PC scan prior to exam date to find if there is any violations - candidates need to remove the violated apps to keep a compliant environment. Also it's suggested to tidy up the room for your exam. Personally I will suggest to temporarily move all books, screens, and all things with printed letters out of room and it's better to give yourself a couple of days to get used to it.</p></li><li><p>The exam style is similar to AWS cert exam. However, the weight among the exam guideline mentioned areas are not described with percentage. Some of the topics are not available to practice with OCI free tier account. It's not required to practice them but if it's possible, getting some credit to play around will be helpful.</p></li><li><p>The last chapter of Oracle University free training offers a sample exam. It's suggested to use the sample exam to get familiar with the multiple-choice exam style and pace. The author suggests readers to keep 1 min for 1 problem and reminder yourself don't spend much time on a single problem.</p></li><li><p>Security is a significant feature and a saling point of OCI. Readers are suggested to take special care on the availability, integrity and confidentiality, e.g. DDoS attack prevention and SSL certificate configurations.</p></li></ul><p>(TBC)</p><p>PS: The promotion of free cert exam is extended to end of year. Hopefully learner around the world could make a better use of time in pandemic while WFH(work-from-home).</p><h2 id="change-log">Change Log</h2><p>May10, 2021: Took OCI Architect Associate Cert Exam and acquired the cert</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/PomqC9ws.png&quot; title=&quot;OCI Architect Associate Cert Link&quot; /&gt;&lt;/p&gt;
&lt;p&gt;OCI (Oracle Cloud Infrastructure) launched free learning and certifcate exam promotion in 2021. I took the exam on May 10, 2021 and acquired the score 89% at the firs attempt. A &lt;a href=&quot;https://www.credly.com/badges/aa7fb3e1-0e2c-41f2-b4ad-a3c862bf6265&quot;&gt;OCI Certificate Badge&lt;/a&gt; will be available within couple of steps in a following email when you knocked the cert exam - usually within 2 working days. Here are some tips shared with readers.&lt;/p&gt;
    
    </summary>
    
      <category term="Cloud" scheme="https://www.maxwu.me/categories/Cloud/"/>
    
      <category term="OCI" scheme="https://www.maxwu.me/categories/Cloud/OCI/"/>
    
    
      <category term="Cloud" scheme="https://www.maxwu.me/tags/Cloud/"/>
    
      <category term="Certificate" scheme="https://www.maxwu.me/tags/Certificate/"/>
    
      <category term="OCI" scheme="https://www.maxwu.me/tags/OCI/"/>
    
  </entry>
  
  <entry>
    <title>2020, The Silent Year</title>
    <link href="https://www.maxwu.me/2021/05/01/2020-The-Silent-Year/"/>
    <id>https://www.maxwu.me/2021/05/01/2020-The-Silent-Year/</id>
    <published>2021-04-30T12:00:00.000Z</published>
    <updated>2021-04-30T12:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.imgur.com/PNmam0sm.jpg" title="Otaki Kite Festival" /></p><blockquote><p>The picture was taken on Otaki Kite Festival 2020. The little penguin, teddy bear and other little buddies are driving the virus(played by a puffer fish kite) out of the their home land. 2 months later, the country-wide lock-down is announced.</p></blockquote><h2 id="april-2020-to-april-2021-the-silent-year.">April 2020 to April 2021, the silent year.</h2><span id="more"></span><p>I started new job as Senior Cloud Native Developer to develop and maintain the devops pipelines and stand cloud stacks for global internal partners from Dec 2019. The first season was full of fun. We spent a happy holiday back to Nanjing, visited relatives and friends, enjoyed the Shanghai Disney tour. I walked through the pipelines, rehearsalled small innovation, developed tools to streamline the stack standing works and glad to see the team liked it - on the united objective to speed up cloud stack delivery. I also flied to Sydney for an on-site training.</p><p><img src="https://i.imgur.com/M5wPmDUm.jpg" title="Lockdown in Yard Tree House" /></p><blockquote><p>Revised 6 months later</p></blockquote><p>The covid-19 suddenly changed many things. We stayed home together to fight the pandemic. We placed orders online - I still remember in the first few weeks the countdown delivery slots were only available on Mon and Wed certain time, it became fully booked quickly. We struggled to learn how do do home schooling - which was hard for young kids to focus on zoon screen and read interested information from the unfamiliar atomsphere of anxiety. I confess I didn't realize human beings have such a strong adaptability to get ourselves used to new life pattern quietly.</p><p>One of the facts is there is no blog update from April 2020 to April 2021. We were not always locked down - actually in most of time there were no realistic restrictions to domestic activities. Material shortage was resolved in 2-3 months. I had the chance to design and implemnet the orchestration core python package and it worked beyond expectations. Then I joined another project where my initiatives were implemented to equip a data-model to Etcd data and off-load the network-flow applications. As long as working from home, I could see a high productivity. In life balance, we spent a lovely Christmas holiday in Hawksbay. I read a list of books via eReader on Python, Golang, k8s, walked thru blogcasts like blockchain and history topics. I even learned how to build mobile apps with React-Native and built new toys with my own firebase account. During the phase, I created an online group of badminton - it has 50+ local members now and we play games each Sat. However, there were also many things happened which we could only absorb by ourselves with family supports. Our behavior patterns are changed, slowly and unnoticeably in the background.</p><p>But when I take a retrospective, I could feel lackness of participation. It's not straightly related to productivity or innovation - it's an engagement with buddies in multiple dimensions, local community, technical meetups, friends and family. When we reduce face-to-face social activities, the online activities are also impacted. In facts I have a better productivity in work and self-studies but less chance to summarize the progressed topics. The action plan is straight - looking around and reaching out to people.</p><p>I draft a short list of topics and start to take periodical time to have a look around, summarize and share the thoughts and feelings. Buddies know I've taken systemtical badminton training for a while, yes - badminton for sure is one of them. I will share the lessons and experiences in movement correction, footworks, power stroke, jump smash and how to do self-training in yard. Large size event is still restricted - for example the Cloud Native Summit NZ has been postponed - but small get-gether within a few people is still okay for the time being - there are plenty of chances to join local associate catch-ups and local golang, cloud, rust workshops.</p><p>The list includes below topics and targeted to 50% coverage in 12 months</p><ul><li><p>Python Programming Tips: generic data model, borg pattern, commander pattern</p></li><li><p>Golang Programming Topics: k8s operator programming, CRD object model, declarative API design, k8s ingress management</p></li><li><p>Devops Topics: migrating apps in helm chart, charts for DevOps, open application model</p></li><li><p>Badminton Topics: Footworks, Power Stroke, Smash Practice Points, attack patterns in mixed double games</p></li><li><p>(Pending): Sharing the stories in India and US travels of early years</p></li><li><p>(Pending): Wellington attractive locations, Local technical communities</p></li></ul><p>Hi 2021, a late greeting ü§ù</p><h2 id="change-log">Change Log</h2><p>Nov21, 2021: Re-post the image and re-deploy with updated hexo config. May01, 2021: Initial post draft.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/PNmam0sm.jpg&quot; title=&quot;Otaki Kite Festival&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The picture was taken on Otaki Kite Festival 2020. The little penguin, teddy bear and other little buddies are driving the virus(played by a puffer fish kite) out of the their home land. 2 months later, the country-wide lock-down is announced.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;april-2020-to-april-2021-the-silent-year.&quot;&gt;April 2020 to April 2021, the silent year.&lt;/h2&gt;
    
    </summary>
    
      <category term="Writing" scheme="https://www.maxwu.me/categories/Writing/"/>
    
    
      <category term="Covid19" scheme="https://www.maxwu.me/tags/Covid19/"/>
    
  </entry>
  
  <entry>
    <title>Borg Pattern in Python Programming</title>
    <link href="https://www.maxwu.me/2021/04/19/Borg-Pattern-in-Python-Programming/"/>
    <id>https://www.maxwu.me/2021/04/19/Borg-Pattern-in-Python-Programming/</id>
    <published>2021-04-18T12:00:00.000Z</published>
    <updated>2021-04-18T12:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.imgur.com/cWIpOi8s.png" title="Borg" /></p><p>"Borg" are a hive-mind collective - Star Trek. The term describes a pattern of shared information among multiple instances :_)</p><p>In most cases of app state sharing, the design really cares about a set of states can be share among components not whether it's one single object in runtime. Python Borg Pattern is easier and flexible to create shared states for other packages to access and use. It's helpful in configuration management, global IDs or session reusing.</p><span id="more"></span><p>(TBD)</p><h2 id="references">References</h2><ul><li><a href="https://www.oreilly.com/library/view/python-cookbook/0596001673/ch05s23.html">Oreilly Python Cookboo</a></li></ul><h2 id="change-log">Change Log</h2><p>Apr19, 2017: Initial post draft.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/cWIpOi8s.png&quot; title=&quot;Borg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&quot;Borg&quot; are a hive-mind collective - Star Trek. The term describes a pattern of shared information among multiple instances :_)&lt;/p&gt;
&lt;p&gt;In most cases of app state sharing, the design really cares about a set of states can be share among components not whether it&#39;s one single object in runtime. Python Borg Pattern is easier and flexible to create shared states for other packages to access and use. It&#39;s helpful in configuration management, global IDs or session reusing.&lt;/p&gt;
    
    </summary>
    
      <category term="Programming" scheme="https://www.maxwu.me/categories/Programming/"/>
    
      <category term="Python" scheme="https://www.maxwu.me/categories/Programming/Python/"/>
    
    
      <category term="Python" scheme="https://www.maxwu.me/tags/Python/"/>
    
      <category term="Borg" scheme="https://www.maxwu.me/tags/Borg/"/>
    
      <category term="Shared State" scheme="https://www.maxwu.me/tags/Shared-State/"/>
    
  </entry>
  
  <entry>
    <title>Using Multi-Stage Build to Reduce Docker Image Size</title>
    <link href="https://www.maxwu.me/2019/11/24/Using-Multi-Stage-Build-to-Reduce-Docker-Image-Size/"/>
    <id>https://www.maxwu.me/2019/11/24/Using-Multi-Stage-Build-to-Reduce-Docker-Image-Size/</id>
    <published>2019-11-24T10:51:09.000Z</published>
    <updated>2019-11-24T10:51:09.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://imgur.com/adsP1G1"><img src="https://i.imgur.com/adsP1G1t.png" alt="Docker on the Producing Line" /></a></p><p>The multi-stage supports in docker image building was introduced with Docker v17.05 in 2017. This post summarizes the practical points which can benefit the development experience, secure the data and reduce the docker image size.</p><span id="more"></span><h2 id="multi-stage-in-docker-image-building">Multi-Stage in Docker Image Building</h2><p>The multi-stage docker image build, in my practices, shows a way to resolve thress issues.</p><ul><li><p>Data Security Supports: If there are previous steps to download the source, setting up the toolchain then there is a risk to leak information via incomplete deletion or to introudce more vulnerability by leaving the artifacts building toolchain on product images. Some cloud solution vendor offers special solution to build artifacts with homogeneous images and only delivery final artifacts in last image.</p></li><li><p>Reducing Docker Image Size: Docker image build generate new layer on each command and the AUFS applies <code>Lazy Deletion</code>. If caches and temporary files are removed in second command, the size wouldn't be reduced from volume but just those files are marked as deleted in the new layer. As pointed by many <code>Dockerfile Best Practice</code> or guidelines, there are recommended tricky steps to keep the <code>dotnet build</code>, <code>yun install</code> or <code>apt-get install</code> followed by purges. Multi-stage build could resolve it by copying artifacts from another stage.</p></li><li><p>Easy to Maintain Dockerfile: The above two issues could be mitigated with well configured multiple images in a procedure to deliver the final artifacts only in last image. However, the Dockerfiles would have dependencies and the Dockerfile would be hard to maintain.</p></li></ul><p>Multi-stage build was introduced to divide the docker image build into multiple stages which can pass artifacts from one to another and eventually ship the final artifacts in the last stage.</p><h2 id="examples-to-reduce-docker-image">Examples to Reduce Docker Image</h2><p>Take an example of upgrading googl-chrome browser version. The base image is <code>cypress/browers</code>.</p><h3 id="upgrade-google-chrome-without-purging-the-cache">Upgrade Google-Chrome without Purging the Cache</h3><p>The Dockefile is straight through: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FROM cypress/browsers:node11.13.0-chrome73</span><br><span class="line"></span><br><span class="line">ENV TZ=Pacific/Auckland</span><br><span class="line"></span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install google-chrome-stable -y &amp;&amp; \</span><br><span class="line">    google-chrome --version</span><br></pre></td></tr></table></figure></p><p>From the logs, it shows chrome browser v78 replaced original v73. To check the image size, either <code>docker images</code> with labels/tags to show a summary on matched images or <code>docker inspect</code> command can show image details.</p><p>Then <code>docker inspect cypress3-chrome-updated-without-purge | jq '.[0].Size'</code> would show the image szie <code>1520046216</code> in Bytes. Alternatively, the docker command native <code>JSON</code> filer could be applied to get the same result on given image <code>docker inspect cypress3-chrome-updated-without-purge --format='\&#123;\&#123;.Size\&#125;\&#125;'</code>.</p><h3 id="upgrade-google-chrome-and-purge-the-cache-immediately">Upgrade Google-Chrome and Purge the Cache Immediately</h3><p>Apply the recommended hacks to clean the cache on every command:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FROM cypress/browsers:node11.13.0-chrome73</span><br><span class="line"></span><br><span class="line">ENV TZ=Pacific/Auckland</span><br><span class="line"></span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install google-chrome-stable \</span><br><span class="line">    -y --no-install-recommends &amp;&amp; \</span><br><span class="line">    rm -rf /var/lib/apt/lists/* &amp;&amp; \</span><br><span class="line">    google-chrome --version</span><br></pre></td></tr></table></figure><p>This way the image size is reduced to 1503569359 Bytes. 200MB caches are removed from the same layer to upgrade chrome browser.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; docker inspect cypress3-chrome-updated-cache-purged  --format=&#x27;&#123;&#123;.Size&#125;&#125;&#x27;</span><br><span class="line">&gt; 1503569359</span><br></pre></td></tr></table></figure><p>Obviously the Dockerfile is a bit harder to maintain because each step was appended with all kinds of purge commands. If there is no convenient way to purge right away or it is difficult to maintain such code in one command, a script might be drafted and copied to the intermediate layers to support such a command in one step.</p><h3 id="generate-the-same-image-in-multi-stage-build">Generate the Same Image in Multi-Stage Build</h3><p>With a quick check, the google chrome is maintained in <code>/opt/google/chrome</code> folder and as an image for experiments, it is okay not to consider apt-get checksums. The new Dockerfile is drafted as below:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FROM cypress/browsers:node11.13.0-chrome73 as stage1</span><br><span class="line"></span><br><span class="line">ENV TZ=Pacific/Auckland</span><br><span class="line"></span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install google-chrome-stable \</span><br><span class="line">    -y --no-install-recommends &amp;&amp; \</span><br><span class="line">    rm -rf /var/lib/apt/lists/* &amp;&amp; \</span><br><span class="line">    google-chrome --version</span><br><span class="line"></span><br><span class="line">FROM cypress/browsers:node11.13.0-chrome73</span><br><span class="line">COPY --from=stage1 /opt/google/chrome /opt/google/chrome</span><br><span class="line">RUN google-chrome --version</span><br></pre></td></tr></table></figure><p>The first image is also homogeneous and it just contribute the google-chrome binary files. Then the final image <code>copied</code> the binaries directly to corresponding folder.</p><p>Test the google-chrome version in cli.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; docker run -it cypress3-chrome-updated-multi-stages google-chrome --version</span><br><span class="line">&gt; Google Chrome 78.0.3904.108</span><br></pre></td></tr></table></figure><p>Check the image size and it shows even a smaller size than that from Dockerfile to purge apt-get system caches because this solution only copies the required folder.</p><p><code>docker inspect cypress3-chrome-updated-multi-stages  --format='\&#123;\&#123;\.Size\&#125;\&#125;'</code> reports size as <code>1501127204</code> Bytes.</p><h3 id="summary">Summary</h3><ul><li><p>Less information left on image: No need to keep addition YUM repos if it is an RHEL image, no extra keys left, more important, no development phase configuration or source code left on image.</p></li><li><p>Smaller size: Since copying the artifacts is the clean way to add only requested files to final image, the size is only increased for neccessary.</p></li></ul><table><thead><tr class="header"><th>Building way</th><th style="text-align: center;">Size</th></tr></thead><tbody><tr class="odd"><td>Install pkg from apt-get</td><td style="text-align: center;">1520046216</td></tr><tr class="even"><td>Install pkg and purge</td><td style="text-align: center;">1503569359</td></tr><tr class="odd"><td>Copying binaries from previous stage</td><td style="text-align: center;">1501127204</td></tr></tbody></table><h2 id="further-discussion">Further Discussion</h2><p>A better chance to apply multi-stage docker image building is to support multi-stage compilation. One typical example is to upgrade git version on an RHEL Jenkins Slave Image. RHEL official YUM repo only supplies the old version of git client. Which doesn't support the advanced functions as Dotnet Core NuGet operations. In this case, the solution is to download git source code and install gcc toolchain to build it locally. Without multi-stage image build, the procedure would request a cross compilation on source code in separate script or build it on docker image directly for homogeneous arch. Multi-stage docker image build can maintain the steps in one single Dockerfile.</p><p>On the other side, the sample in this post is not an apt example. If only the chrome binary executable files under /opt/google/chrome are updated staightly, the /etc/alternative would still point to chrome-stable binary but the apt pkg management DB still regard it as the original version v73, not the current version and the dependencies check won't cover v78 neither. Like Sun Solaris package system, it is possible to overwrite the package DB but which would request one more command and consequently a new docker image layer. The apt package DB is located at /var/lib/apt/lists.</p><p>So apply multi-stage image build for source code compilation especially multi-stage compilation, decompressed binary package as Node.js.</p><p>(TBC)</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://imgur.com/adsP1G1&quot;&gt;&lt;img src=&quot;https://i.imgur.com/adsP1G1t.png&quot; alt=&quot;Docker on the Producing Line&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The multi-stage supports in docker image building was introduced with Docker v17.05 in 2017. This post summarizes the practical points which can benefit the development experience, secure the data and reduce the docker image size.&lt;/p&gt;
    
    </summary>
    
      <category term="Cloud" scheme="https://www.maxwu.me/categories/Cloud/"/>
    
      <category term="Docker" scheme="https://www.maxwu.me/categories/Cloud/Docker/"/>
    
    
      <category term="Cloud" scheme="https://www.maxwu.me/tags/Cloud/"/>
    
      <category term="Docker" scheme="https://www.maxwu.me/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Still On the Way to Cloud</title>
    <link href="https://www.maxwu.me/2019/11/11/Still-On-the-Way-to-Cloud/"/>
    <id>https://www.maxwu.me/2019/11/11/Still-On-the-Way-to-Cloud/</id>
    <published>2019-11-11T10:00:20.000Z</published>
    <updated>2019-11-11T10:00:20.000Z</updated>
    
    <content type="html"><![CDATA[<p>It is the last quarter of 2019. A large number of organizations already deployed docker containerized applications in production environment and usually the services are orchestrated with kubernetes or Openshift. As the well known saying, just moving applications to cloud doesn't mean clouding, we are still in the middle of way to cloud. This post is also a retrospective on the issues discovered this year on migrating traditional technical stacks to cloud.</p><p>(WIP)</p><figure><img src="https://i.imgur.com/zApN0Gsm.jpg" alt="Docker_Kube" /><figcaption aria-hidden="true">Docker_Kube</figcaption></figure><span id="more"></span><h2 id="typical-issues-on-sensitivity-of-container-environment">1 Typical issues on sensitivity of container environment</h2><h3 id="dotnet-core-2.1-pod-restarted-on-oom-killer">1.1 Dotnet core 2.1 Pod restarted on OOM Killer</h3><p>This was the first issue I spent a big effort this year to realize that popular technical stacks were still not ready to adapt themselves to container environment. Typically if a managed system reads the mount point <code>/proc/self/mountinfo</code> as on regular Linux platform but not the <code>/proc/self/cgroup</code>, the memory limits are not observable from the memory management.</p><p>The github link is https://github.com/dotnet/coreclr/issues/13489. The fix includes https://github.com/dotnet/coreclr/pull/13488 and https://github.com/dotnet/coreclr/pull/15297 to check cgroup resource limits and expose docker processor counts to CLR environments.</p><p>The phenomenon was dotnet core pod restarted more than 200 times per day and openshift monitor portal showed <code>OOM Killer</code> in event description. It was lukcy the production environment deployed with replica number 4 so fintech service was not interrupted. To debug this issue, an image of LLDB on dotnet core was created to detect threading model and high memory blocks (https://maxwu.me/2019/04/15/Debug-dotnet-core-with-LLDB-on-RHEL-Image/). Per my observation, the high runners are Newtonsoft JSON entities because lots of memory were consumed by dotnet string buffers.</p><h3 id="jenkins-pipeline-ran-out-of-memory">1.2 Jenkins Pipeline ran out of memory</h3><p>This issue is actually a JVM configuration problem. It was dicovered when Jenkins pod ran slowly in one day and Jenkins pod was observed to restart within 72hr everytime. Our Pipeline was a typical Jenkins groovy Pipeline and it communicated to two kinds of slaves: (1) the dynamical jenkins slave created on demand, which were based on different slave images with required technical stack; (2) windows slaves for specific tasks which could only complete by Windows nodes for time being.</p><p>(TBC)</p><h3 id="cypress-failed-to-launch-xvfb-in-docker-container">1.3 Cypress failed to launch XVFB in docker container</h3><p>Cypress is the in browser javascript UI test framework I picked for team last year (2018) when migrated from host based Selenium to Pipeline.</p><p>(TBC)</p><h3 id="golang-routine-gomaxprocs-issue-in-container-environment">1.4 Golang Routine GOMAXPROCS Issue in Container Environment</h3><p>Go developers could use <code>runtime.GOMAXPROCS()</code> to set the threads limit of go runtime (number of P of MPGmodel) or read it when setting value is <code>0</code>. From golang v1.5 the default value is the core number of CPU. However, when running in a container, the go runtime still read the core numbers from host, not the container resource limit.</p><p>There is a workaround from Uber <code>automaxprocs</code> lib. By <code>import _ "go.uber.org/automaxprocs"</code>, the <code>automaxprocs</code> lib initializer will read the core number from container <code>cgroup</code> limit and set the <code>GOMAXPROCS</code> automatically.</p><p>(TBC)</p><h2 id="typical-issues-on-container-orchestration">2 Typical issues on container orchestration</h2><h3 id="orchestrating-cypress-tests-in-map-reduce-model-on-kube-cloud">2.1 Orchestrating Cypress tests in Map-Reduce model on kube cloud</h3><h3 id="rolling-out-springboot-pod-generated-alert-flooding-on-splunk">2.2 Rolling out springboot pod generated alert flooding on splunk</h3><h2 id="retrospective">3 Retrospective</h2><h2 id="change-log">Change Log</h2><p>May 01, 2021: Add golang routing burst issue Nov 12, 2019: Initial post with intro part and the outline.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;It is the last quarter of 2019. A large number of organizations already deployed docker containerized applications in production environment and usually the services are orchestrated with kubernetes or Openshift. As the well known saying, just moving applications to cloud doesn&#39;t mean clouding, we are still in the middle of way to cloud. This post is also a retrospective on the issues discovered this year on migrating traditional technical stacks to cloud.&lt;/p&gt;
&lt;p&gt;(WIP)&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/zApN0Gsm.jpg&quot; alt=&quot;Docker_Kube&quot; /&gt;&lt;figcaption aria-hidden=&quot;true&quot;&gt;Docker_Kube&lt;/figcaption&gt;
&lt;/figure&gt;
    
    </summary>
    
      <category term="Cloud" scheme="https://www.maxwu.me/categories/Cloud/"/>
    
      <category term="Docker" scheme="https://www.maxwu.me/categories/Cloud/Docker/"/>
    
    
      <category term="Cloud" scheme="https://www.maxwu.me/tags/Cloud/"/>
    
      <category term="Docker" scheme="https://www.maxwu.me/tags/Docker/"/>
    
      <category term="Openshift" scheme="https://www.maxwu.me/tags/Openshift/"/>
    
  </entry>
  
  <entry>
    <title>A Bite of SpringBoot</title>
    <link href="https://www.maxwu.me/2019/09/28/A-Bite-Of-Springboot/"/>
    <id>https://www.maxwu.me/2019/09/28/A-Bite-Of-Springboot/</id>
    <published>2019-09-28T08:37:33.000Z</published>
    <updated>2019-09-28T08:37:33.000Z</updated>
    
    <content type="html"><![CDATA[<p>The journey to migrate dotnet experiences to springboot and build a demo app from scratch, deploy it to kubernetes with explanation on technical points and the cloud native practice notes.</p><span id="more"></span><h2 id="background">Background</h2><p>As a pythonist on system level, I built several my experience with Java Web Frameworks are mostly on structs MVC as an UI backend to interact with JQuery to present the status and management from message security gateway products. However, according to the reality of circumstance, framework seems much more impressive than computer science and ways of thoughts.</p><p>It's the time to take a bite on Springboot and see what's inside.</p><h2 id="environment">1 Environment</h2><p>In brief, Jetbrain IntelliJ community version on Mac. I used to program Python on PyCharm and IntelliJ shares similar features on Java IDE.</p><p>Java toolchain will be organized in Gradle. Maven is an alternative which I used in previous test automation tools. However, gradle is graceful and brief.</p><p>Eventually the service will be wrapped in kubernetes pod but it is not the first step.</p><h2 id="create-a-new-springboot-app">2 Create A New Springboot App</h2><p>Springboot web site offers <code>curl</code> interface to generate a demo project to start from. Visit https://start.spring.io on cli tool curl will show the manual on how to generate springboot scaffold.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl https://start.spring.io</span><br><span class="line"># The response shows a manual page with below samples.</span><br><span class="line">Examples:</span><br><span class="line"></span><br><span class="line">To create a default demo.zip:</span><br><span class="line">$ curl https://start.spring.io/starter.zip -o demo.zip</span><br><span class="line"></span><br><span class="line">To create a web project using Java 11:</span><br><span class="line">$ curl https://start.spring.io/starter.zip -d dependencies=web \\</span><br><span class="line">-d javaVersion=11 -o demo.zip</span><br><span class="line"></span><br><span class="line">To create a web/data-jpa gradle project unpacked:</span><br><span class="line">$ curl https://start.spring.io/starter.tgz -d dependencies=web,data-jpa \\</span><br><span class="line">   -d type=gradle-project -d baseDir=my-dir | tar -xzvf -</span><br><span class="line"></span><br><span class="line">To generate a Maven POM with war packaging:</span><br><span class="line">$ curl https://start.spring.io/pom.xml -d packaging=war -o pom.xml</span><br></pre></td></tr></table></figure><p>I chose a demo web project using Java 8. Which means, a wrapped dependency of <code>spring-boot-starter-web</code>. Springboo will interrepte it to real dependencies.</p><p><code>curl https://start.spring.io/starter.zip -d dependencies=web -d javaVersion=8 -d type=gradle-project -o demo.zip</code></p><p>Alternatively, open IntelliJ menu to "New Project" will also provide options to visit <code>start.spring.io</code> within the IDE UI to create project scaffold.</p><h2 id="launch-springboot-demo">3 Launch Springboot Demo</h2><p>When importing the scaffold project to IntelliJ, a run configuration with main class on the <code>DemoApplication</code> , where the annotation <code>@SpringBootApplication</code> is applied, will be created. Run the configuration "DemoApplication" will launch Springboo web app in couple of seconds. However, visiting <code>localhost:8080</code> will still return an error page since there is nothing to respond.</p><p>For the gradle configured project, the IntelliJ would spend a bit while to download gradle dependencies.</p><p>A simple controller class is added to respond string content to path <code>/</code>. Thanks to IntelliJ, the annotations are auto-completed. Key points here are "GetMapping" annotation to specify the path of <code>/</code> and "RespenseBody" annotation t</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.demo;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Controller;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.GetMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.ResponseBody;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MainController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/&quot;)</span></span><br><span class="line">    <span class="meta">@ResponseBody</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">home</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Home&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Like <code>npm run</code> but more verbose than the node.js cmd, luanch <code>./gradlew tasks</code> or directly run <code>gradle tasks</code> in root folder of project would print out a task list which can be run by gradle plugin. If it is the first time running <code>gradle</code>, the gradle daemon shall be luanched and basic environment/dependencies checks would be performed first.</p><p><code>gradlew</code> and <code>gradle.bat</code> are artifacts generated by <code>gradle warpper</code> task which empower environments with gradle preinstalled to run gradle toolchain commands.</p><p>After updating the above controller class, run <code>gradle bootRun</code> would also run the springboot application to server <code>localhost:8080</code>. In the browser, the simple content "Home" is fetched and rendered.</p><h2 id="build-docker-image-for-springboot-app">4 Build Docker Image for Springboot App</h2><p>As usual there are multiple ways to build docker images as first step to containerize the app. Thanks to the gradle community <code>com.palantir.docker</code> plugin is picked up in this demo project.</p><p>The gradle pluin could be applied in build.script DSL or plugin DSL. This experiment applies the plugin DSL and build docker image with Dockerfile rather than docker plugin DSL to reuse author's existing Dockerfile experiences for now.</p><h3 id="add-plugin">4.1 Add Plugin</h3><p>Insert this plugin reference to build.gradle <code>id 'com.palantir.docker' version '0.22.1'</code>.</p><h3 id="introduce-docker-task">4.2 Introduce <code>docker</code> Task</h3><p>The task is defined as below:</p><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">docker &#123;</span><br><span class="line">dependsOn build</span><br><span class="line">name <span class="string">&quot;$&#123;project.group&#125;/$&#123;bootJar.baseName&#125;&quot;</span></span><br><span class="line">files bootJar.archivePath</span><br><span class="line">buildArgs([<span class="string">&#x27;JAR_FILE&#x27;</span>: <span class="string">&quot;$&#123;bootJar.archiveName&#125;&quot;</span>])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="create-the-dockerfile">4.3 Create the Dockerfile</h3><p>To keep the image slim, alpine jdk8 image is picked as base image.</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> openjdk:<span class="number">8</span>-jdk-alpine</span><br><span class="line"><span class="keyword">VOLUME</span><span class="bash"> /tmp</span></span><br><span class="line"><span class="keyword">ARG</span> JAR_FILE</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> <span class="variable">$&#123;JAR_FILE&#125;</span> app.jar</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">&quot;java&quot;</span>,<span class="string">&quot;-Djava.security.egd=file:/dev/./urandom&quot;</span>,<span class="string">&quot;-jar&quot;</span>,<span class="string">&quot;/app.jar&quot;</span>]</span></span><br></pre></td></tr></table></figure><h3 id="launch-container-locally">4.4 Launch Container Locally</h3><p>With above Dockerfile and the <code>docker</code> task inserted to gradle.build script, run <code>gradle docker</code> would (re)build the app image with dependencies. Quickly test the docker image by launching it locally, <code>docker run -p 8080:8080 -t com.example/demo</code>. Then open browser on URL <code>http://localhost:8080/</code> the same contents are responded "Home".</p><h2 id="deploy-to-kubernetes">5 Deploy to Kubernetes</h2><p>(To be continued)</p><h2 id="change-log">Change Log</h2><p>Sep 22, 2019: Configuration and start a new springboot app. Sep 28, 2019:</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The journey to migrate dotnet experiences to springboot and build a demo app from scratch, deploy it to kubernetes with explanation on technical points and the cloud native practice notes.&lt;/p&gt;
    
    </summary>
    
      <category term="Microservice" scheme="https://www.maxwu.me/categories/Microservice/"/>
    
      <category term="Springboot" scheme="https://www.maxwu.me/categories/Microservice/Springboot/"/>
    
    
      <category term="Java" scheme="https://www.maxwu.me/tags/Java/"/>
    
      <category term="Springboot" scheme="https://www.maxwu.me/tags/Springboot/"/>
    
      <category term="Kubernetes" scheme="https://www.maxwu.me/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Fix home brew updating failure</title>
    <link href="https://www.maxwu.me/2019/08/17/Fix-home-brew-updating-failure/"/>
    <id>https://www.maxwu.me/2019/08/17/Fix-home-brew-updating-failure/</id>
    <published>2019-08-17T11:21:51.000Z</published>
    <updated>2019-08-17T11:21:51.000Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h2 id="problem-description">Problem Description</h2><p>After a few weeks sorting up and working with Python3 on my Mac Book Pro, the brew update failed to update and reported an error of aws command not found.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;¬†brew update</span><br><span class="line">aws codecommit credential-helper $@ get: aws: command not found</span><br><span class="line">fatal: could not read Username for &#x27;https://github.com/Homebrew/homebrew-boneyard&#x27;: terminal prompts disabled</span><br><span class="line"></span><br><span class="line">^Cerror: https://github.com/caskroom/homebrew-cask did not send all necessary objects</span><br></pre></td></tr></table></figure><h2 id="resolution">Resolution</h2><p>The solution is straight through. Since aws cli is not found, it is a missed step in migrating Mac development environment from Python2 to Python3 -- the corresponding aws cli is not installed well to Python3.</p><p>My python environment is managed via PyEnv. When a new python version is installed, the upstream depeendencies are not maintained via requirement.txt so it needs a manual step to re-enable awscli. ¬† <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;pip3 install awscli --upgrade</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h2 id=&quot;problem-description&quot;&gt;Problem Description&lt;/h2&gt;
&lt;p&gt;After a few weeks sorting up and working with Python3 on my
      
    
    </summary>
    
      <category term="Mac" scheme="https://www.maxwu.me/categories/Mac/"/>
    
    
      <category term="Mac" scheme="https://www.maxwu.me/tags/Mac/"/>
    
      <category term="Brew" scheme="https://www.maxwu.me/tags/Brew/"/>
    
  </entry>
  
  <entry>
    <title>Incrementally measure code coverage</title>
    <link href="https://www.maxwu.me/2019/06/09/Incrementally-measure-code-coverage/"/>
    <id>https://www.maxwu.me/2019/06/09/Incrementally-measure-code-coverage/</id>
    <published>2019-06-09T09:42:34.000Z</published>
    <updated>2019-06-09T09:42:34.000Z</updated>
    
    <content type="html"><![CDATA[<p>For new app or repos with a close to ideal level code coverage, the populor code coverage solution on coverage metrics threshold check would be efficient. However, to maintain a legacy or low coverage level repo, it is not eonough to just check coverage percentage on metrics. This post described an idea to check coverage json diff with istanbul-diff on node.js repos.</p><span id="more"></span><h2 id="problem">Problem</h2><p>Usually in Jenkins Pipeline or SAAS DevOps infrastructure, the code coverage check is implemented with <code>Cobertura</code> or cloud service <code>Coverage</code>.</p><p>As described in previous posts, here are samples of <code>Coverage</code> service and on-premise <code>Cobertura</code>.</p><p><a href="https://i.imgur.com/gtm74Pr.png"><img src="https://i.imgur.com/gtm74Prm.png" alt="Coverage" /></a> <a href="https://i.imgur.com/YHyhOJ7.png"><img src="https://i.imgur.com/YHyhOJ7t.png" alt="Cobertura" /></a></p><p>The coverage check is implemented with metrics and thresholds, in other wors, the score of code coverage on current baseline. This won't be a problem when the repo has an ideal coverage leve.</p><p>For example, if the threshold is set to 95% on lines, functions and branches thress metrics, when the change breaks the threshold, the coverage check will fail.</p><p>On an legacy repo, this would potentially be a problem with a low coverage level. For an example, if the repo has 45% overall lines coverage. On one of the feature branch, the code change lower down some source code coverage by accidently introduced a wrong condition in Jest. But the feature branch aslo introduced a batch of new source and keep 100% on these new added source filed. Therefore, it is possible to see an increase in <code>Total Coverage</code>. And due to a lower level of <code>Cobertura</code> threshold on existing code, this cannot be discovered by the coverage check at all. The feature branch can be merged to master branch with successful coverage endorsement.</p><p>Above is a real case in coverage overall check with one of my projects.</p><h2 id="solution">Solution</h2><p>Since the project mentioned above is a node.js front-end app, the coverage measurement is implemented with Jest coverage. Underneath the jest framework, <a href="https://istanbul.js.org"><code>istanbul</code></a> is the code coverage lib. This triggered me to seek a way to compare the coverage result files from the source branch to target branch.</p><p>The solution could rely on JsonDiff lib to compare the coverage between two branches and fail when there is any nodes on source tree has decrease on coverage unless the leave nodes (file-line, function, branch path) are removed from source branch.</p><p>Here the term <code>leave node</code> depends on which coverage metrics are selected. It could be one or more from lines, functions and branches. The three coverage metrics are supported by istanbul.</p><ul><li><p>The first condition can be satisfied by applying an npm lib <a href="https://github.com/moos/istanbul-diff"><code>istabul-diff</code></a>. Which is based on <code>jsondiffpath</code> lib to compare the increments between source coverage summary and target (existing) one.</p></li><li><p>The second condition would be resolved with traditional way -- <code>Artifactory</code>. On Jenkins Pipeline, a goovy closure will be defined to push coverage-summary JSON to artifactory if current <code>BUILD</code> passes and it is on master branch.</p><p>So the artifactory specific PATH will only keep a latest copy of master branch coverage result (in JSON format).</p><p>When Pipeline determines the build is on a feature branch, it will automatically download the master coverage summary from Artifactory and apply istanbul-diff to find if there is any loss on coverage but will accept all the positive (incremental) coverage.</p></li><li><p>To utilize istanbul-diff tool, istanbul reporter <code>json-summary</code> is required. By default Jest would apply parameter <code>["json", "lcov", "text", "clover"]</code> (refer to <a href="https://jestjs.io/docs/en/configuration#coveragereporters-array-string">Jest Doc</a>)</p><p>So the package.json could be updated as:</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">&quot;jest&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;coverageReporters&quot;</span>: [</span><br><span class="line">      <span class="string">&quot;json&quot;</span>, </span><br><span class="line">      <span class="string">&quot;lcov&quot;</span>, </span><br><span class="line">      <span class="string">&quot;text&quot;</span>, </span><br><span class="line">      <span class="string">&quot;clover&quot;</span>,</span><br><span class="line">      <span class="string">&quot;json-summary&quot;</span></span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="more-topics">More topics</h2><p>The author just verified the idea with a rough react sample but haven't tested the solution with prototype on pipeline yet. Here are actions to fulfill and confirm:</p><ul><li><p>Implement the solution above in an POC branch on pipeline definition file.</p></li><li><p>Take special care to verify when leave nodes are removed, istanbul-diff could accept it not as a failure.</p></li><li><p>When multiple metrics are specified, e.g. both lines and functions, any loss of coverage in one of more of the metrics will fail the final return code.</p></li><li><p>A PR submitted to fix typo in istanbul-diff README Markdown doc, https://github.com/moos/istanbul-diff/pull/3</p></li></ul><h2 id="change-log">Change Log</h2><p>Jun 09, 2019: Initial and roughly tested with sample node.js repo.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;For new app or repos with a close to ideal level code coverage, the populor code coverage solution on coverage metrics threshold check would be efficient. However, to maintain a legacy or low coverage level repo, it is not eonough to just check coverage percentage on metrics. This post described an idea to check coverage json diff with istanbul-diff on node.js repos.&lt;/p&gt;
    
    </summary>
    
      <category term="DevOps" scheme="https://www.maxwu.me/categories/DevOps/"/>
    
      <category term="Coverage" scheme="https://www.maxwu.me/categories/DevOps/Coverage/"/>
    
    
      <category term="Istanbul" scheme="https://www.maxwu.me/tags/Istanbul/"/>
    
      <category term="Coverage" scheme="https://www.maxwu.me/tags/Coverage/"/>
    
      <category term="DevOps" scheme="https://www.maxwu.me/tags/DevOps/"/>
    
  </entry>
  
  <entry>
    <title>Convolutional Neural Networks in TensorFlow</title>
    <link href="https://www.maxwu.me/2019/06/02/Completed-Deeplearning-ai-CNN-in-TensorFlow-A-retro-on-roadmap/"/>
    <id>https://www.maxwu.me/2019/06/02/Completed-Deeplearning-ai-CNN-in-TensorFlow-A-retro-on-roadmap/</id>
    <published>2019-06-02T02:36:23.000Z</published>
    <updated>2019-06-02T02:36:23.000Z</updated>
    
    <content type="html"><![CDATA[<p>Cheers! Completed the Deeplearning.ai course <strong>Convolutional Neural Networks in TensorFlow</strong>.</p><p><a href="https://imgur.com/Gqldzu2"><img src="https://i.imgur.com/Gqldzu2m.png" alt="Deeplearning-ai-cert-tensorflow-ai-ml-dl" /></a></p><p>Following the roadmap, this is the 4th certificates on <a href="https://www.coursera.org">Coursera.org</a> on the Machine Learning path.</p><span id="more"></span><p>Two big application areas are ready to commercialize Machine Learning with more powerful modern CPU or clouds, the computer visioning and NLP. Images and literal words are two main sources to extract features in our minds and so does the ML.</p><table><colgroup><col style="width: 25%" /><col style="width: 25%" /><col style="width: 25%" /><col style="width: 25%" /></colgroup><thead><tr class="header"><th>Course</th><th>Keywords</th><th>Completion Date</th><th>School</th></tr></thead><tbody><tr class="odd"><td><em><strong>Machine Learning</strong></em></td><td>Andrew Ng course as ML 101</td><td>Completed by <code>2017-11-05</code></td><td>Standford University</td></tr><tr class="even"><td><em><strong>Introduction to Data Science in Python</strong></em></td><td>An intro to PyNum and Pandas in Data Science</td><td>4 weeks, Completed by <code>2018-04-08</code></td><td>University of Michigan</td></tr><tr class="odd"><td><em><strong>Convolutional Neural Networks in TensorFlow</strong></em></td><td>Applying CNN with Tensorflow and techniques avoiding overfitting and Transferred learning</td><td>4 weeks, Completed by <code>2019-05-31</code></td><td>deeplearning.ai/coursera</td></tr><tr class="even"><td><em><strong>Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning</strong></em></td><td>TansorFlow and Typical ML technoiques and structures for Images</td><td>4 weeks, Completed by <code>2019-05-04</code></td><td>deeplearning.ai/coursera</td></tr><tr class="odd"><td><strong>Course TBD, Machine Learing in NLP</strong></td><td>Applying ML to NLP, chatbots</td><td>TODO: next step</td><td>TBD</td></tr></tbody></table><p>As on above table, the next bite will be NLP. Let's move up, buddies!</p><p><a href="https://imgur.com/g9mL59p"><img src="https://i.imgur.com/g9mL59pm.png" alt="ML_Roadmap_draft_1" /></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Cheers! Completed the Deeplearning.ai course &lt;strong&gt;Convolutional Neural Networks in TensorFlow&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://imgur.com/Gqldzu2&quot;&gt;&lt;img src=&quot;https://i.imgur.com/Gqldzu2m.png&quot; alt=&quot;Deeplearning-ai-cert-tensorflow-ai-ml-dl&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Following the roadmap, this is the 4th certificates on &lt;a href=&quot;https://www.coursera.org&quot;&gt;Coursera.org&lt;/a&gt; on the Machine Learning path.&lt;/p&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="https://www.maxwu.me/categories/Machine-Learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Completed Deeplearning.ai TensorFlow Introdution Course</title>
    <link href="https://www.maxwu.me/2019/05/05/Completed-Deeplearning-ai-TensorFlow-Introdution-Course/"/>
    <id>https://www.maxwu.me/2019/05/05/Completed-Deeplearning-ai-TensorFlow-Introdution-Course/</id>
    <published>2019-05-05T11:37:15.000Z</published>
    <updated>2019-05-05T11:37:15.000Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><p>Hurray! Completed the Deeplearning.ai course <strong>Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning</strong> and achieved the certificate on coursera!</p><p><a href="https://imgur.com/Gqldzu2"><img src="https://i.imgur.com/Gqldzu2m.png" alt="Deeplearning-ai-cert-tensorflow-intro" /></a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;p&gt;Hurray! Completed the Deeplearning.ai course &lt;strong&gt;Introduction to TensorFlow for Artificial Intelligence, Mach
      
    
    </summary>
    
      <category term="Machine Learning" scheme="https://www.maxwu.me/categories/Machine-Learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Customized domain for github page with hexo</title>
    <link href="https://www.maxwu.me/2019/05/01/Customized-domain-for-github-page-with-hexo/"/>
    <id>https://www.maxwu.me/2019/05/01/Customized-domain-for-github-page-with-hexo/</id>
    <published>2019-05-01T10:02:08.000Z</published>
    <updated>2019-05-01T10:02:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>After upgrading hexo and dependencies in local repo package.json, when regenerating the github pages and pushed to remote repo, the customized domain starts to respond 404.</p><p>Check github, the way to add customized domain is to add a CNAME file with each domain in one line. If user tries to manaully configure his/her own domain on github settings tab, a CNAME file will be pegged automatically by github. However, the manually grown CNAME file will be purged in next posting time if hexo is not correctly configured.</p><p>Searching the hexo document, the place to hold this CNAME file is not local repo root folder but the root folder of hexo theme. In My case, it is <code>./themes/next-wuxubj-5.0.2/</code>. If your hexo applies other theme, please change to the corresponding folder name. This way, the CNAME file will be preserved.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;After upgrading hexo and dependencies in local repo package.json, when regenerating the github pages and pushed to remote repo, the custo
      
    
    </summary>
    
      <category term="Github" scheme="https://www.maxwu.me/categories/Github/"/>
    
    
      <category term="Github" scheme="https://www.maxwu.me/tags/Github/"/>
    
      <category term="Hexo" scheme="https://www.maxwu.me/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>Debug dotnet core with LLDB on RHEL Image</title>
    <link href="https://www.maxwu.me/2019/04/15/Debug-dotnet-core-with-LLDB-on-RHEL-Image/"/>
    <id>https://www.maxwu.me/2019/04/15/Debug-dotnet-core-with-LLDB-on-RHEL-Image/</id>
    <published>2019-04-15T10:25:42.000Z</published>
    <updated>2019-04-15T10:25:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>This post is based on a quick note on how to create a docker image for openshift/k8s to debug dotnet core app with LLD online in the containter environment.</p><span id="more"></span><h2 id="problem">Problem</h2><p>(TBC)</p><h2 id="solution">Solution</h2><p>It will request a Red Hat developer account to register to RHN when trying to enable <code>rhel-7-server-devtools-rpms</code> RPM repo on Red Hat. However, if it is a docker environment, which is not required to register the docker instance to RHN to add this repo. So the repo could be enabled in Dockerfile. Then the LLDB toolset would be installed to this image.</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># From a customized RHEL dotnet sdk base image</span></span><br><span class="line"><span class="keyword">FROM</span> dotnet/dotnet-<span class="number">21</span>-rhel7</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Set the timezone</span></span><br><span class="line"><span class="keyword">ENV</span> TZ=XXX</span><br><span class="line"> </span><br><span class="line"><span class="keyword">USER</span> root</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum-config-manager --<span class="built_in">enable</span> rhel-7-server-devtools-rpms</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y wget tcpdump vim llvm-toolset-7</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> rm -rf /opt/app-root/.pki</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">USER</span> <span class="number">1001</span></span><br></pre></td></tr></table></figure><h2 id="how-to-debug-dotnet-core-app-with-lldb">How to debug dotnet core app with LLDB</h2><blockquote><p>(TODO): Push the image to dockerhub and launch more test with AWS environment.</p></blockquote><blockquote><p>Complete this post with more details on how to apply LLDB on memory check and online debug.</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This post is based on a quick note on how to create a docker image for openshift/k8s to debug dotnet core app with LLD online in the containter environment.&lt;/p&gt;
    
    </summary>
    
      <category term="Cloud" scheme="https://www.maxwu.me/categories/Cloud/"/>
    
      <category term="Docker" scheme="https://www.maxwu.me/categories/Cloud/Docker/"/>
    
    
      <category term="LLDB" scheme="https://www.maxwu.me/tags/LLDB/"/>
    
      <category term="DotnetCore" scheme="https://www.maxwu.me/tags/DotnetCore/"/>
    
      <category term="Docker" scheme="https://www.maxwu.me/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Acquired AWS Solution Architecture Professional (SAP) and DevOps Professional (DOP) Certificates</title>
    <link href="https://www.maxwu.me/2018/11/07/Acquired-AWS-Solution-Architecture-and-DevOps-Professional-Certificates/"/>
    <id>https://www.maxwu.me/2018/11/07/Acquired-AWS-Solution-Architecture-and-DevOps-Professional-Certificates/</id>
    <published>2018-11-07T05:50:29.000Z</published>
    <updated>2018-11-07T05:50:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>When participating the project to migrate Web Service and full pipeline to openshift, it is worthy to continue AWS study to professional level and compare the SAAS hybrid solution to on-premise PAAS with openshift.</p><p>These two certificates were achieved during the above project <code>Evolve</code>.</p><p><a href="https://imgur.com/1KAF74s.png"><img src="https://i.imgur.com/1KAF74sm.png" alt="AWS_DOP" /></a> <a href="https://imgur.com/JyZn4PX.png"><img src="https://i.imgur.com/1KAF74sm.png" alt="AWS_DOP" /></a></p><span id="more"></span>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;When participating the project to migrate Web Service and full pipeline to openshift, it is worthy to continue AWS study to professional level and compare the SAAS hybrid solution to on-premise PAAS with openshift.&lt;/p&gt;
&lt;p&gt;These two certificates were achieved during the above project &lt;code&gt;Evolve&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://imgur.com/1KAF74s.png&quot;&gt;&lt;img src=&quot;https://i.imgur.com/1KAF74sm.png&quot; alt=&quot;AWS_DOP&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;https://imgur.com/JyZn4PX.png&quot;&gt;&lt;img src=&quot;https://i.imgur.com/1KAF74sm.png&quot; alt=&quot;AWS_DOP&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Cloud" scheme="https://www.maxwu.me/categories/Cloud/"/>
    
      <category term="AWS" scheme="https://www.maxwu.me/categories/Cloud/AWS/"/>
    
    
      <category term="AWS - SAP - DOP" scheme="https://www.maxwu.me/tags/AWS-SAP-DOP/"/>
    
  </entry>
  
  <entry>
    <title>Michigan Data Science with Python Course Achieved</title>
    <link href="https://www.maxwu.me/2018/04/09/Michigan-Data-Science-with-Python-Course-Achieved/"/>
    <id>https://www.maxwu.me/2018/04/09/Michigan-Data-Science-with-Python-Course-Achieved/</id>
    <published>2018-04-08T12:04:50.000Z</published>
    <updated>2018-04-08T12:04:50.000Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><p>Completed the 2nd data science course and achieved the certificate on coursera!</p><figure><img src="https://i.imgur.com/gE39kX4m.png" alt="Imgur Michigan Data Science with Python Course Cert" /><figcaption aria-hidden="true">Imgur Michigan Data Science with Python Course Cert</figcaption></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;p&gt;Completed the 2nd data science course and achieved the certificate on coursera!&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;https://i.
      
    
    </summary>
    
      <category term="Machine Learning" scheme="https://www.maxwu.me/categories/Machine-Learning/"/>
    
    
      <category term="Python" scheme="https://www.maxwu.me/tags/Python/"/>
    
      <category term="Data Science" scheme="https://www.maxwu.me/tags/Data-Science/"/>
    
  </entry>
  
  <entry>
    <title>Update Anaconda-Navigator thru command line</title>
    <link href="https://www.maxwu.me/2018/03/19/Update-Anaconda-Navigator-thru-command-line/"/>
    <id>https://www.maxwu.me/2018/03/19/Update-Anaconda-Navigator-thru-command-line/</id>
    <published>2018-03-18T20:23:35.000Z</published>
    <updated>2018-03-18T20:23:35.000Z</updated>
    
    <content type="html"><![CDATA[<figure><img src="https://i.imgur.com/xFQI6dtl.png" alt="Anaconda-Navigator" /><figcaption aria-hidden="true">Anaconda-Navigator</figcaption></figure><span id="more"></span><h2 id="update-anaconda-navigator">Update Anaconda-Navigator</h2><p>After the Machine Learning course, I registered Data Science Introduction course (Michigan Univ.) to refresh Python hands. When the pop-up asking about updating anaconda navigator to a new version, I selected "yes" and it just quit current anaconda navigaotr window on Mac. However, Anaconda-Navigator only shut down without any updates. It might be due some permission issue.</p><p>Here is the command line to update Anaconda-Navigator: <code>conda update anaconda-navigator</code>. To execute the correct command in cases of pyenv installed to wrap multiple python contexts, you need to select the anaconda pyenv profile and set it to local (or global if intent to).</p><h2 id="update-anaconda-environment">Update Anaconda Environment</h2><p>To update anaconda current environment to the latest packages unless dependencies preserve some package versions, the command line is <code>conda update conda</code> Another way to launch the terminal is to click Anaconda GUI environment column and select "Open Terminal" from the small triangle.</p>]]></content>
    
    <summary type="html">
    
      &lt;figure&gt;
&lt;img src=&quot;https://i.imgur.com/xFQI6dtl.png&quot; alt=&quot;Anaconda-Navigator&quot; /&gt;&lt;figcaption aria-hidden=&quot;true&quot;&gt;Anaconda-Navigator&lt;/figcaption&gt;
&lt;/figure&gt;
    
    </summary>
    
      <category term="Programming" scheme="https://www.maxwu.me/categories/Programming/"/>
    
      <category term="Python" scheme="https://www.maxwu.me/categories/Programming/Python/"/>
    
    
      <category term="Python" scheme="https://www.maxwu.me/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://www.maxwu.me/tags/Anaconda/"/>
    
  </entry>
  
  <entry>
    <title>Stanford A-NG Machine Learning Certificate Achieved</title>
    <link href="https://www.maxwu.me/2017/11/12/Stanford-A-NG-Machine-Learning-Certificate-Achieved/"/>
    <id>https://www.maxwu.me/2017/11/12/Stanford-A-NG-Machine-Learning-Certificate-Achieved/</id>
    <published>2017-11-12T09:37:15.000Z</published>
    <updated>2017-11-12T09:37:15.000Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><p>Completed the first machine learning course and achieved the certificate on coursera!</p><p>Rather than warming up mathematics and scripting with new toy of octave(and matlab), it was an experience to enhance time management :_)</p><figure><img src="https://i.imgur.com/6WmFoUsm.png" alt="Stanford-Andrew-Ng-ML-Course-Cert" /><figcaption aria-hidden="true">Stanford-Andrew-Ng-ML-Course-Cert</figcaption></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;p&gt;Completed the first machine learning course and achieved the certificate on coursera!&lt;/p&gt;
&lt;p&gt;Rather than warming 
      
    
    </summary>
    
      <category term="Machine Learning" scheme="https://www.maxwu.me/categories/Machine-Learning/"/>
    
    
      <category term="Machine Learning" scheme="https://www.maxwu.me/tags/Machine-Learning/"/>
    
      <category term="Andrew-Ng" scheme="https://www.maxwu.me/tags/Andrew-Ng/"/>
    
      <category term="Stanford" scheme="https://www.maxwu.me/tags/Stanford/"/>
    
  </entry>
  
  <entry>
    <title>Greeting Shell script with Picture show and Weathre Forecast</title>
    <link href="https://www.maxwu.me/2017/09/28/Greeting-Shell-script-with-Picture-show-and-Weathre-Forecast/"/>
    <id>https://www.maxwu.me/2017/09/28/Greeting-Shell-script-with-Picture-show-and-Weathre-Forecast/</id>
    <published>2017-09-27T12:53:18.000Z</published>
    <updated>2017-09-27T12:53:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>"<strong>iterm2 greeting with weather and image</strong>" is a short shell made for bash_profil invoke to weather forecast based on GeoIP, a quote of greeting, and, show a random picture from given folder.</p><span id="more"></span><h2 id="introduction">Introduction</h2><p>It is created to make use of Friday evening and show my daughter's random picture each time a terminal window is created. After a quick family demo show, I added cli arguments support the next day „ã°</p><h2 id="features">Features</h2><p><a href="https://i.imgur.com/VR53tEE.png"><img src="https://i.imgur.com/VR53tEEm.png" alt="greeting" /></a></p><ul><li>Show randmo picture from folder.<ul><li>It follows iTerm2 (on Mac) imgcat extended protocols.</li><li>Picture will be resized to given width in cols or 40 by default</li><li>Picture folder is specified or defaulted to ~/Pictures.</li></ul></li><li>Fetch weathre forecast from wttr.in.</li><li>Adjust format according to current terminal window width.</li></ul><p>Github Link: <a href="https://github.com/maxwu/iterm2_greeting_with_weather_img">https://github.com/maxwu/iterm2_greeting_with_weather_img</a></p><h2 id="change-log">Change Log</h2><p>May28, 2017: Initial post.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&quot;&lt;strong&gt;iterm2 greeting with weather and image&lt;/strong&gt;&quot; is a short shell made for bash_profil invoke to weather forecast based on GeoIP, a quote of greeting, and, show a random picture from given folder.&lt;/p&gt;
    
    </summary>
    
      <category term="Programming" scheme="https://www.maxwu.me/categories/Programming/"/>
    
      <category term="Shell" scheme="https://www.maxwu.me/categories/Programming/Shell/"/>
    
    
      <category term="iterm2" scheme="https://www.maxwu.me/tags/iterm2/"/>
    
      <category term="shell" scheme="https://www.maxwu.me/tags/shell/"/>
    
      <category term="imgcat" scheme="https://www.maxwu.me/tags/imgcat/"/>
    
  </entry>
  
</feed>
